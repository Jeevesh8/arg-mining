{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "long_context_am.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOATDbqtjxmUZOTkXRUzyaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeevesh8/arg_mining/blob/main/experiments/long_context_am.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOGdooHmfgd-"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GPY8HXWtkyE"
      },
      "source": [
        "%%capture\n",
        "#if running on colab, install below 4\n",
        "#!git clone https://github.com/Jeevesh8/arg_mining\n",
        "#!pip install transformers\n",
        "#!pip install seqeval datasets allennlp\n",
        "#!pip install flax\n",
        "\n",
        "#if connected to local runtime, run the next command too\n",
        "#pip install bs4 tensorflow torch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs8QzJCbx9lO"
      },
      "source": [
        "\n",
        "\n",
        "*   Update ``arg_mining/datasets/cmv_modes/configs.py`` as per your requirements, all experiments considered till now, set ``batch_size`` to 2, and all other variables with their default value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_glbajGinKG4"
      },
      "source": [
        "#Run to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pCBwYZjfkHw"
      },
      "source": [
        "### Load Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkKUqJo4e_Rc"
      },
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric('seqeval')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35kJb8EE0Fm-"
      },
      "source": [
        "### Krippendorff's Alpha Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik1XOXUu0FOw"
      },
      "source": [
        "from typing import List, Tuple\n",
        "import re\n",
        "\n",
        "class krip_alpha():\n",
        "    \"\"\"A module for computing sentence level Krippendorff's Alpha,\n",
        "    for argumentative components  annotated at the token level. Must use\n",
        "    labels [\"B-C\", \"B-P\"].\n",
        "    \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"See self.compute_metric() for what each of these data actually mean.\n",
        "        \"\"\"\n",
        "        self.pred_has_claim = 0\n",
        "        self.ref_has_claim = 0\n",
        "        self.pred_has_premise = 0\n",
        "        self.ref_has_premise = 0\n",
        "        \n",
        "        self.claim_wise_agreement = 0\n",
        "        self.premise_wise_agreement = 0\n",
        "        \n",
        "        self.claim_wise_disagreement = 0\n",
        "        self.premise_wise_disagreement = 0\n",
        "    \n",
        "        self.total_sentences = 0\n",
        "        \n",
        "        self.has_both_ref = 0\n",
        "        self.has_both_pred = 0\n",
        "        self.has_none_ref = 0\n",
        "        self.has_none_pred = 0\n",
        "\n",
        "    def preprocess(self, threads: List[List[int]]) -> List[List[List[int]]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            threads:    A list of all threads in a batch. A thread is a list of \n",
        "                        integers corresponding to token_ids of the tokens in the \n",
        "                        thread.\n",
        "        Returns:\n",
        "            A List with all the threads, where each thread now consists of \n",
        "            sentence lists. Where, a sentence list in a thread list is the list \n",
        "            of token_ids corresponding to a sentence in a thread. \n",
        "        \"\"\"\n",
        "        threads_lis = []\n",
        "\n",
        "        for i, thread in enumerate(threads):\n",
        "            sentence = []\n",
        "            threads_lis.append([])\n",
        "            for j, token_id in enumerate(thread):\n",
        "                if token_id==tokenizer.pad_token_id:\n",
        "                    break\n",
        "                \n",
        "                sentence.append(token_id)\n",
        "                token = tokenizer.convert_ids_to_tokens(token_id)\n",
        "                #print(\"appended token:\", token)\n",
        "\n",
        "                next_token = 'None' if j==len(thread) else tokenizer.convert_ids_to_tokens(thread[j+1])\n",
        "\n",
        "                if (token.count('.')+token.count('?')+token.count('!')>=1 and \n",
        "                    next_token.count('.')+next_token.count('?')+next_token.count('!')==0):\n",
        "\n",
        "                    threads_lis[i].append(sentence)\n",
        "                    #print(\"Sample sentence: \", tokenizer.decode(sentence))\n",
        "                    sentence = []\n",
        "                \n",
        "                elif re.findall(r\"\\[USER\\d+\\]|\\[UNU\\]\", token)!=[]:\n",
        "                    prev_part = tokenizer.decode(sentence[:-1])[1:-1]\n",
        "                    if re.search(r'[a-zA-Z]', prev_part) is not None:\n",
        "                        threads_lis[i].append(sentence[:-1])\n",
        "                        #print(\"Sample sentence just befor user token:\", tokenizer.decode(sentence[:-1]))\n",
        "                        sentence = [sentence[-1]]\n",
        "                    else:\n",
        "                        k=len(sentence)-2\n",
        "                        while k>=0 and sentence[k]==tokenizer.convert_tokens_to_ids('Ġ'):\n",
        "                            k-=1\n",
        "                        sentence = sentence[k+1:]\n",
        "                        threads_lis[i][-1] += sentence[:k]\n",
        "                        #print(\"Sample sentence just befor user token:\", tokenizer.decode(threads_lis[i][-1]))\n",
        "                \n",
        "            has_rem_token = False\n",
        "            for elem in sentence:\n",
        "                if (elem!=tokenizer.convert_tokens_to_ids('Ġ') and\n",
        "                    elem!=tokenizer.eos_token_id):\n",
        "                    has_rem_token = True\n",
        "                    break\n",
        "            \n",
        "            if has_rem_token:\n",
        "                threads_lis[i].append(sentence)\n",
        "                #print(\"Sample sentence at end of thread: \", tokenizer.decode(sentence))\n",
        "                sentence = []\n",
        "\n",
        "        return threads_lis\n",
        "\n",
        "    def get_sentence_wise_preds(self, threads: List[List[List[int]]], \n",
        "                                      predictions: List[List[str]]) -> List[List[List[str]]]:\n",
        "        \"\"\"Splits the prediction corresponding to each thread, into predictions\n",
        "        for each sentence in the corresponding thread in \"threads\" list.\n",
        "        Args:\n",
        "            threads:      A list of threads, where each thread consists of further \n",
        "                          lists corresponding to the various sentences in the\n",
        "                          thread. [As output by self.preprocess()]\n",
        "            predictions:  A list of predictions for each thread, in the threads\n",
        "                          list. Each prediciton consists of a list of componenet \n",
        "                          types corresponding to each token in a thread.\n",
        "        Returns:\n",
        "            The predictions list, with each prediction split into predictions \n",
        "            corresponding to the sentences in the corresponding thread specified\n",
        "            in the threads list. \n",
        "        \"\"\"\n",
        "        sentence_wise_preds = []\n",
        "        for i, thread in enumerate(threads):\n",
        "            next_sentence_beg = 0\n",
        "            sentence_wise_preds.append([])\n",
        "            for sentence in thread:\n",
        "                sentence_wise_preds[i].append(\n",
        "                    predictions[i][next_sentence_beg:next_sentence_beg+len(sentence)])\n",
        "                next_sentence_beg += len(sentence)\n",
        "        return sentence_wise_preds\n",
        "    \n",
        "    def update_state(self, pred_sentence: List[str], ref_sentence: List[str]) -> None:\n",
        "        \"\"\"Updates the various information maintained for the computation of\n",
        "        Krippendorff's alpha, based on the predictions(pred_sentence) and \n",
        "        references(ref_sentence) provided for a particular sentence, in some \n",
        "        thread.\n",
        "        \"\"\"\n",
        "        self.total_sentences += 1\n",
        "        \n",
        "        if 'B-C' in pred_sentence:\n",
        "            self.pred_has_claim += 1\n",
        "            if 'B-C' in ref_sentence:\n",
        "                self.ref_has_claim += 1\n",
        "                self.claim_wise_agreement += 1\n",
        "            else:\n",
        "                self.claim_wise_disagreement += 1\n",
        "            \n",
        "        elif 'B-C' in ref_sentence:\n",
        "            self.ref_has_claim += 1\n",
        "            self.claim_wise_disagreement += 1\n",
        "        \n",
        "        else:\n",
        "            self.claim_wise_agreement += 1\n",
        "        \n",
        "        if 'B-P' in pred_sentence:\n",
        "            self.pred_has_premise += 1\n",
        "            if 'B-P' in ref_sentence:\n",
        "                self.ref_has_premise += 1\n",
        "                self.premise_wise_agreement += 1\n",
        "            else:\n",
        "                self.premise_wise_disagreement += 1\n",
        "\n",
        "        elif 'B-P' in ref_sentence:\n",
        "            self.ref_has_premise += 1\n",
        "            self.premise_wise_disagreement += 1\n",
        "        \n",
        "        else:\n",
        "            self.premise_wise_agreement += 1\n",
        "        \n",
        "        if 'B-C' in pred_sentence and 'B-P' in pred_sentence:\n",
        "            self.has_both_pred += 1\n",
        "        \n",
        "        if 'B-C' in ref_sentence and 'B-P' in ref_sentence:\n",
        "            self.has_both_ref += 1\n",
        "        \n",
        "        if 'B-C' not in pred_sentence and 'B-P' not in pred_sentence:\n",
        "            self.has_none_pred += 1\n",
        "        \n",
        "        if 'B-C' not in ref_sentence and 'B-P' not in ref_sentence:\n",
        "            self.has_none_ref += 1\n",
        "        return\n",
        "\n",
        "    def add_batch(self, predictions: List[List[str]], \n",
        "                  references: List[List[str]], \n",
        "                  tokenized_threads: List[List[int]]) -> None:\n",
        "        \"\"\"Add a batch of predictions and references for the computation of \n",
        "        Krippendorff's alpha.\n",
        "        Args:\n",
        "            predictions:      A list of predictions for each thread, in the \n",
        "                              threads list. Each prediciton consists of a list \n",
        "                              of component types corresponding to each token in \n",
        "                              a thread.\n",
        "            references:       Same structure as predictions, but consisting of \n",
        "                              acutal gold labels, instead of predicted ones.\n",
        "            tokenized_thread: A list of all threads in a batch. A thread is a \n",
        "                              list of integers corresponding to token_ids of the\n",
        "                              tokens in the thread.\n",
        "        \"\"\"\n",
        "        threads = self.preprocess(tokenized_threads)\n",
        "        \n",
        "        sentence_wise_preds = self.get_sentence_wise_preds(threads, predictions)\n",
        "        sentence_wise_refs = self.get_sentence_wise_preds(threads, references)\n",
        "\n",
        "        for pred_thread, ref_thread in zip(sentence_wise_preds, sentence_wise_refs):\n",
        "            for pred_sentence, ref_sentence in zip(pred_thread, ref_thread):\n",
        "                self.update_state(pred_sentence, ref_sentence)\n",
        "\n",
        "    def compute(self, print_additional: bool=True) -> None:\n",
        "        \"\"\"Prints out the metric, for the batched added till now. And then \n",
        "        resets all data being maintained by the metric. \n",
        "        Args:\n",
        "            print_additional:   If True, will print all the data being \n",
        "                                maintained instead of just the Krippendorff's \n",
        "                                alphas for claims and premises.\n",
        "        \"\"\"\n",
        "        print(\"Sentence level Krippendorff's alpha for Claims: \", 1-(self.claim_wise_disagreement/(self.claim_wise_agreement+self.claim_wise_disagreement))/0.5)\n",
        "        print(\"Sentence level Krippendorff's alpha for Premises: \", 1-(self.premise_wise_disagreement/(self.premise_wise_agreement+self.premise_wise_disagreement))/0.5)\n",
        "        \n",
        "        if print_additional:\n",
        "            print(\"Additional attributes: \")\n",
        "            print(\"\\tTotal Sentences:\", self.total_sentences)\n",
        "            print(\"\\tPrediction setences having claims:\", self.pred_has_claim)\n",
        "            print(\"\\tPrediction sentences having premises:\", self.pred_has_premise)\n",
        "            print(\"\\tReference setences having claims:\", self.ref_has_claim)\n",
        "            print(\"\\tReference sentences having premises:\", self.ref_has_premise)\n",
        "            print(\"\\n\")\n",
        "            print(\"\\tPrediction Sentence having both claim and premise:\", self.has_both_pred)\n",
        "            print(\"\\tPrediction Sentence having neither claim nor premise:\", self.has_none_pred)\n",
        "            print(\"\\tReference Sentence having both claim and premise:\", self.has_both_ref)\n",
        "            print(\"\\tReference Sentence having neither claim nor premise:\", self.has_none_ref)\n",
        "            print(\"\\n\")\n",
        "            print(\"\\tSentences having claim in both reference and prediction:\", self.claim_wise_agreement)\n",
        "            print(\"\\tSentences having claim in only one of reference or prediction:\", self.claim_wise_disagreement)\n",
        "            print(\"\\tSentences having premise in both reference and prediction:\", self.premise_wise_agreement)\n",
        "            print(\"\\tSentences having premise in only one of reference or prediction:\", self.premise_wise_disagreement)\n",
        "        self.__init__()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYRNv0wBWtFd"
      },
      "source": [
        "metric = krip_alpha()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjf6BxMkfm3R"
      },
      "source": [
        "### Define & Load Tokenizer, Model, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wcsqmllnfRB"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45DeXxCDS_id",
        "outputId": "b0ca5aed-d8b2-4e1b-9c58-50b645eaedc7"
      },
      "source": [
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHRkCQOZu6HS"
      },
      "source": [
        "model_version = 'allenai/longformer-base-4096'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6cB-7M9t0HP"
      },
      "source": [
        "%%capture\n",
        "from transformers import LongformerTokenizer, AutoModel\n",
        "tokenizer = LongformerTokenizer.from_pretrained(model_version)\n",
        "transformer_model = AutoModel.from_pretrained(model_version).to(device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ajTzrbzkwbT"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "#Extend Token Type Embeddings\n",
        "def resize_token_type_embeddings(transformer_model, new_size):\n",
        "    old_embeddings = transformer_model.embeddings.token_type_embeddings.weight\n",
        "    old_size, hidden_dim = old_embeddings.shape\n",
        "    transformer_model.embeddings.token_type_embeddings = nn.Embedding(new_size, hidden_dim, device=transformer_model.device)\n",
        "    with torch.no_grad():\n",
        "        transformer_model.embeddings.token_type_embeddings.weight[:old_size] = old_embeddings\n",
        "\n",
        "#resize_token_type_embeddings(transformer_model, 2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p6dGA83cGVS"
      },
      "source": [
        "with open('./Discourse_Markers.txt') as f:\n",
        "    discourse_markers = [dm.strip() for dm in f.readlines()]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTCeCgbLxVyQ"
      },
      "source": [
        "%%capture\n",
        "from arg_mining.datasets.cmv_modes import load_dataset, data_config\n",
        "\n",
        "tokenizer.add_tokens(data_config[\"special_tokens\"])\n",
        "\n",
        "transformer_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def get_datasets():\n",
        "    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n",
        "                                                              train_sz=80,\n",
        "                                                              test_sz=20,\n",
        "                                                              mask_tokens=discourse_markers)\n",
        "    return train_dataset, valid_dataset, test_dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi_8gVbufzoX"
      },
      "source": [
        "### Define layers for a Linear-Chain-CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seBwkZdByesM"
      },
      "source": [
        "from allennlp.modules.conditional_random_field import ConditionalRandomField as crf\n",
        "\n",
        "ac_dict = data_config[\"arg_components\"]\n",
        "\n",
        "allowed_transitions =([(ac_dict[\"B-C\"], ac_dict[\"I-C\"]), \n",
        "                       (ac_dict[\"B-P\"], ac_dict[\"I-P\"])] + \n",
        "                      [(ac_dict[\"I-C\"], ac_dict[ct]) \n",
        "                        for ct in [\"I-C\", \"B-C\", \"B-P\", \"O\"]] +\n",
        "                      [(ac_dict[\"I-P\"], ac_dict[ct]) \n",
        "                        for ct in [\"I-P\", \"B-C\", \"B-P\", \"O\"]] +\n",
        "                      [(ac_dict[\"O\"], ac_dict[ct]) \n",
        "                        for ct in [\"O\", \"B-C\", \"B-P\"]])\n",
        "                    \n",
        "linear_layer = nn.Linear(transformer_model.config.hidden_size,\n",
        "                         len(ac_dict)).to(device)\n",
        "\n",
        "crf_layer = crf(num_tags=len(ac_dict),\n",
        "                constraints=allowed_transitions,\n",
        "                include_start_end_transitions=False).to(device)\n",
        "\n",
        "cross_entropy_layer = nn.CrossEntropyLoss(weight=torch.log(torch.tensor([3.3102, 61.4809, 3.6832, 49.6827, 2.5639], \n",
        "                                                                        device=device)), reduction='none')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUicsK33f9d7"
      },
      "source": [
        "### Global Attention Mask Utility for Longformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOSo7p2I5mOi"
      },
      "source": [
        "import numpy as np\n",
        "from threading import Lock\n",
        "\n",
        "def get_global_attention_mask(tokenized_threads: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Returns an attention mask, with 1 where there are [USER{i}] tokens and \n",
        "    0 elsewhere.\n",
        "    \"\"\"\n",
        "    mask = np.zeros_like(tokenized_threads)\n",
        "    for user_token in [\"UNU\"]+[f\"[USER{i}]\" for i in range(data_config[\"max_users\"])]:\n",
        "        user_token_id = tokenizer.encode(user_token)[1:-1]\n",
        "        mask = np.where(tokenized_threads==user_token_id, 1, mask)\n",
        "    return np.array(mask, dtype=bool)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp4PLQihf5CT"
      },
      "source": [
        "### Loss and Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL3u8eH1rjZe"
      },
      "source": [
        "from typing import Tuple"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuJ5aryW9tUC"
      },
      "source": [
        "def compute(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
        "            preds: bool=False, cross_entropy: bool=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        batch:  A tuple having tokenized thread of shape [batch_size, seq_len],\n",
        "                component type labels of shape [batch_size, seq_len], and a global\n",
        "                attention mask for Longformer, of the same shape.\n",
        "        \n",
        "        preds:  If True, returns a List(of batch_size size) of Tuples of form \n",
        "                (tag_sequence, viterbi_score) where the tag_sequence is the \n",
        "                viterbi-decoded sequence, for the corresponding sample in the batch.\n",
        "        \n",
        "        cross_entropy:  This argument will only be used if preds=False, i.e., if \n",
        "                        loss is being calculated. If True, then cross entropy loss\n",
        "                        will also be added to the output loss.\n",
        "    \n",
        "    Returns:\n",
        "        Either the predicted sequences with their scores for each element in the batch\n",
        "        (if preds is True), or the loss value summed over all elements of the batch\n",
        "        (if preds is False).\n",
        "    \"\"\"\n",
        "    tokenized_threads, token_type_ids, comp_type_labels, global_attention_mask = batch\n",
        "    \n",
        "    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n",
        "    \n",
        "    logits = linear_layer(transformer_model(input_ids=tokenized_threads,\n",
        "                               attention_mask=pad_mask,\n",
        "                               global_attention_mask=global_attention_mask).last_hidden_state)\n",
        "    \n",
        "    if preds:\n",
        "        return crf_layer.viterbi_tags(logits, pad_mask)\n",
        "    \n",
        "    log_likelihood = crf_layer(logits, comp_type_labels, pad_mask)\n",
        "    \n",
        "    if cross_entropy:\n",
        "        logits = logits.reshape(-1, logits.shape[-1])\n",
        "        \n",
        "        pad_mask, comp_type_labels = pad_mask.reshape(-1), comp_type_labels.reshape(-1)\n",
        "        \n",
        "        ce_loss = torch.sum(pad_mask*cross_entropy_layer(logits, comp_type_labels))\n",
        "        \n",
        "        return ce_loss - log_likelihood\n",
        "\n",
        "    return -log_likelihood"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot6lkPCsgEY4"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-yfpzEMBGra"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n",
        "                                      linear_layer.parameters(),\n",
        "                                      crf_layer.parameters()),\n",
        "                       lr = 2e-5,)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdSWnkO8gLD6"
      },
      "source": [
        "### Training And Evaluation Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTNaP3kLaN2X"
      },
      "source": [
        "def train(dataset):\n",
        "    accumulate_over = 4\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, (tokenized_threads, masked_threads, comp_type_labels, _ ) in enumerate(dataset):\n",
        "        global_attention_mask = torch.tensor(get_global_attention_mask(tokenized_threads),\n",
        "                                             device=device, dtype=torch.int32)\n",
        "        \n",
        "        #Remove Device Axis and cast to PyTorch tensor\n",
        "        tokenized_threads = torch.tensor(np.squeeze(tokenized_threads, axis=0), \n",
        "                                         device=device)\n",
        "        masked_threads = torch.tensor(np.squeeze(masked_threads, axis=0), \n",
        "                                      device=device)\n",
        "        comp_type_labels = torch.tensor(np.squeeze(comp_type_labels, axis=0), \n",
        "                                        device=device, dtype=torch.long)\n",
        "        \n",
        "        global_attention_mask = torch.squeeze(global_attention_mask, dim=0)\n",
        "        \n",
        "        loss = compute((tokenized_threads,\n",
        "                        torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n",
        "                        comp_type_labels, \n",
        "                        global_attention_mask))/data_config[\"batch_size\"]\n",
        "        \n",
        "        print(\"Loss: \", loss)\n",
        "        loss.backward()\n",
        "        \n",
        "        if i%accumulate_over==accumulate_over-1:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "    \n",
        "    optimizer.step()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeHJiT0sjXid"
      },
      "source": [
        "#transformer_model.config.type_vocab_size = 2"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7BpSI83cU24"
      },
      "source": [
        "def evaluate(dataset, metric):\n",
        "    \n",
        "    int_to_labels = {v:k for k, v in ac_dict.items()}\n",
        "    \n",
        "    for tokenized_threads, masked_threads, comp_type_labels, _ in dataset:\n",
        "        \n",
        "        global_attention_mask = torch.tensor(get_global_attention_mask(tokenized_threads), \n",
        "                                             device=device)\n",
        "        \n",
        "        #Remove Device Axis and cast to PyTorch tensor\n",
        "        tokenized_threads = torch.tensor(np.squeeze(tokenized_threads, axis=0),\n",
        "                                        device=device)\n",
        "        masked_threads = torch.tensor(np.squeeze(masked_threads, axis=0),\n",
        "                                     device=device)\n",
        "        comp_type_labels = torch.tensor(np.squeeze(comp_type_labels, axis=0),\n",
        "                                        device=device)\n",
        "        global_attention_mask = torch.squeeze(global_attention_mask, dim=0)\n",
        "        \n",
        "        preds = compute((tokenized_threads,\n",
        "                         torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n",
        "                         comp_type_labels,\n",
        "                         global_attention_mask),\n",
        "                        preds=True)\n",
        "        \n",
        "        lengths = torch.sum(torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0), \n",
        "                            axis=-1)\n",
        "        \n",
        "        preds = [ [int_to_labels[pred] for pred in pred[0][:lengths[i]]]\n",
        "                  for i, pred in enumerate(preds)\n",
        "                ]\n",
        "        \n",
        "        refs = [ [int_to_labels[ref] for ref in labels[:lengths[i]]]\n",
        "                 for i, labels in enumerate(comp_type_labels.cpu().tolist())\n",
        "               ]\n",
        "        \n",
        "        metric.add_batch(predictions=preds, \n",
        "                         references=refs,)\n",
        "                         #tokenized_threads=tokenized_threads.cpu().tolist())\n",
        "    \n",
        "    print(metric.compute())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZV6rnIQgOYA"
      },
      "source": [
        "### Final Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O2O5qCufGwA"
      },
      "source": [
        "n_epochs = 35"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30xcK9sOgX44",
        "outputId": "34bf0371-68f1-4f07-c997-ceeba7e7758e"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    print(f\"------------EPOCH {epoch+1}---------------\")\n",
        "    train_dataset, _, test_dataset = get_datasets()\n",
        "    train(train_dataset)\n",
        "    evaluate(test_dataset, metric)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------EPOCH 1---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n",
            "2021-08-29 08:22:15.204781: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2021-08-29 08:22:15.205535: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(2973.9468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2462.3704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3139.0212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2966.9358, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1952.8796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1946.5880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2418.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2577.3245, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1671.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1805.9352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1897.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2940.4619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2384.5071, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3558.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3496.2034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2329.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2072.3525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(866.5177, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1586.3795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1024.2919, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1981.6472, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1253.6990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2019.9214, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1441.8145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3245.8677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6091.0273, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3391.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3486.5759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1394.2505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1270.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1167.3799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2797.2573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1794.2727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1791.3098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2645.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(875.9709, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2852.8438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5073.1709, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1487.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3025.7461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1891.6333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3221.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2899.7983, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4165.1187, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1617.2249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.02, 'recall': 0.010676156583629894, 'f1': 0.013921113689095127, 'number': 281}, 'P': {'precision': 0.07749469214437367, 'recall': 0.1524008350730689, 'f1': 0.10274454609429978, 'number': 479}, 'overall_precision': 0.0695970695970696, 'overall_recall': 0.1, 'overall_f1': 0.08207343412526998, 'overall_accuracy': 0.5387833274532534}\n",
            "------------EPOCH 2---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(2273.0903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1841.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2471.6355, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2164.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1606.8018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1576.8586, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1838.8578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1885.7168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1252.7092, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1329.5139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1437.3618, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2201.5513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1911.2617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3098.7412, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2827.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1842.6409, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1783.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(764.2330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1372.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(859.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1622.7849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1023.5544, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1619.1890, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1168.8148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2655.7458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5208.8779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2918.2666, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3125.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1207.8984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1143.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1029.7014, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2438.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1497.7871, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1430.8123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2292.7600, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(788.7428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2552.8218, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4483.7856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1366.7566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2502.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1754.5092, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2935.5327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2520.0132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3723.2195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1512.2113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.024390243902439025, 'recall': 0.0071174377224199285, 'f1': 0.011019283746556474, 'number': 281}, 'P': {'precision': 0.08914728682170543, 'recall': 0.1440501043841336, 'f1': 0.11013567438148443, 'number': 479}, 'overall_precision': 0.08294392523364486, 'overall_recall': 0.09342105263157895, 'overall_f1': 0.08787128712871287, 'overall_accuracy': 0.5790030744418124}\n",
            "------------EPOCH 3---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(2079.5879, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1789.7952, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2354.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2061.2212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1578.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1529.5566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1713.4924, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1700.9150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1038.1912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1181.0385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1277.1396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1954.8271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1481.9486, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2547.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2475.2139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1598.6050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1524.2825, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(692.5863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1190.7092, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(766.1627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1398.5513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(922.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1448.7362, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1005.8262, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2398.3611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4796.0713, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2573.8267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2776.8662, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1094.7351, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1071.0325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(956.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2226.4624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1370.5149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1278.7500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2123.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(730.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2373.9504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4150.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1216.7576, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2179.9717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1540.1626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2665.7637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2432.7783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3513.0430, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1248.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.20642201834862386, 'recall': 0.1601423487544484, 'f1': 0.18036072144288579, 'number': 281}, 'P': {'precision': 0.14483627204030228, 'recall': 0.24008350730688935, 'f1': 0.18067556952081695, 'number': 479}, 'overall_precision': 0.15810276679841898, 'overall_recall': 0.21052631578947367, 'overall_f1': 0.18058690744920994, 'overall_accuracy': 0.6213900509046923}\n",
            "------------EPOCH 4---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1717.7151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1430.9900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1927.7095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1613.2534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1178.5215, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1165.5503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1384.1243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1444.6191, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(962.6447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1091.9529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1148.6304, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1793.7053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1360.0070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2469.3438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2328.4275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1534.5162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1355.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(666.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1060.8434, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(681.6495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1166.0940, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(836.3973, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1264.7856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(811.1871, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2022.4395, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4152.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2063.7490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2302.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(915.0574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(927.9081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(809.0386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2004.9423, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1198.9907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1064.1411, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1894.9253, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(655.0762, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2166.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3685.3022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1059.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1801.3401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1337.6519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2437.8408, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2145.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3104.5378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1073.4878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.22692307692307692, 'recall': 0.2099644128113879, 'f1': 0.21811460258780038, 'number': 281}, 'P': {'precision': 0.33053221288515405, 'recall': 0.49269311064718163, 'f1': 0.3956412405699916, 'number': 479}, 'overall_precision': 0.3028747433264887, 'overall_recall': 0.3881578947368421, 'overall_f1': 0.34025374855824686, 'overall_accuracy': 0.6528400786250693}\n",
            "------------EPOCH 5---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1441.2290, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1236.4598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1623.9893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1337.7258, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1044.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1012.6123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1236.6392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1237.1589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(754.8901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(864.7780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(928.7760, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1526.5376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(898.7935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1780.5334, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1920.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1243.1511, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1054.3442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(636.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1002.5032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(602.5770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1006.8289, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(827.0662, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1118.7020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(679.7429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1730.2321, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3704.6323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1638.3896, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1761.5333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(722.4628, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(707.6126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(608.0688, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1666.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(961.0208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(813.3849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1647.5250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(565.0173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1895.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3256.1367, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(968.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1558.1543, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1241.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2295.9971, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1873.6449, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2685.9541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(894.3863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.27722772277227725, 'recall': 0.398576512455516, 'f1': 0.327007299270073, 'number': 281}, 'P': {'precision': 0.5407554671968191, 'recall': 0.5678496868475992, 'f1': 0.5539714867617107, 'number': 479}, 'overall_precision': 0.42337375964718854, 'overall_recall': 0.5052631578947369, 'overall_f1': 0.46070785842831435, 'overall_accuracy': 0.6620130033768459}\n",
            "------------EPOCH 6---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1182.4780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1095.6685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1397.6470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1114.9705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(716.6255, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(605.8184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(895.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(902.4107, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(583.5878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(721.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(717.7845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1254.0278, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(673.4452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1342.8739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1600.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1003.2498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(796.8303, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(486.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(814.1244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(492.3235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(841.1235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(711.8702, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(938.5797, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(463.5371, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1519.2197, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3200.9817, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1239.3459, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1413.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(567.9750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(514.6958, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(457.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1341.7212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(752.9820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(613.5060, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1506.0083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(498.0229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1345.5880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2590.0508, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(731.6372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1257.0338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1056.4333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1976.4020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1314.2716, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1959.4856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(744.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.24742268041237114, 'recall': 0.1708185053380783, 'f1': 0.20210526315789476, 'number': 281}, 'P': {'precision': 0.39095744680851063, 'recall': 0.6137787056367432, 'f1': 0.47766043866774976, 'number': 479}, 'overall_precision': 0.36152219873150104, 'overall_recall': 0.45, 'overall_f1': 0.40093786635404455, 'overall_accuracy': 0.6563681266065219}\n",
            "------------EPOCH 7---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1428.7117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1329.9863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1716.8959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(980.7017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(445.9598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(475.8095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(757.0668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(788.8951, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(419.8482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(545.4813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(691.6328, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1297.7152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(559.9841, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1151.9441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1478.5205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(835.6366, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(810.4703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(432.1743, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(739.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(474.8658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(986.7693, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(752.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1027.0081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(466.9889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1458.8682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3147.7793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(865.4413, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1120.7299, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(544.5657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(402.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(356.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1193.4580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(657.6845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(424.1724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1446.4016, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(478.8383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1256.6804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2545.7676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(786.5663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1154.8910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(860.5820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1654.5859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1149.0063, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1751.3843, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(651.9424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.281505728314239, 'recall': 0.6120996441281139, 'f1': 0.38565022421524664, 'number': 281}, 'P': {'precision': 0.6638176638176638, 'recall': 0.48643006263048016, 'f1': 0.5614457831325301, 'number': 479}, 'overall_precision': 0.420997920997921, 'overall_recall': 0.5328947368421053, 'overall_f1': 0.47038327526132406, 'overall_accuracy': 0.617912403608689}\n",
            "------------EPOCH 8---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(991.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(952.7816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1198.5479, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(908.8898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(490.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(323.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(714.1186, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(690.5570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(377.4210, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(512.3388, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(525.6669, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1333.3190, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(496.8885, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1192.0198, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1144.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(795.6533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(639.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(337.8582, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(620.5691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(430.6666, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(578.5113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(498.9923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(584.6334, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(303.5832, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1130.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2508.7705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(901.8248, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1063.7263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(372.5793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(316.0007, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(344.0650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(997.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(685.8419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(819.7446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1483.7595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(408.6031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(909.4535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2935.0955, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(753.4374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1432.7949, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(659.8983, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1269.8339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1025.0393, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1511.0787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(428.9437, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.37790697674418605, 'recall': 0.2313167259786477, 'f1': 0.28697571743929357, 'number': 281}, 'P': {'precision': 0.48400556328233657, 'recall': 0.7265135699373695, 'f1': 0.5809682804674458, 'number': 479}, 'overall_precision': 0.46352413019079686, 'overall_recall': 0.5434210526315789, 'overall_f1': 0.5003028467595396, 'overall_accuracy': 0.6938662365808175}\n",
            "------------EPOCH 9---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1113.3750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(786.3789, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1352.0734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(668.4664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(457.7811, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(433.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(727.7462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(543.8607, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(373.8029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(613.0286, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(597.3057, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1307.4272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(436.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1002.9071, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1170.0320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(851.7665, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(727.8351, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(339.4643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(710.3964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(444.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(726.5755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(580.0770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(819.4207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(426.4546, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1653.4862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3607.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1303.7308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1831.3966, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(326.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(302.4178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(329.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1001.7626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(394.7242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(357.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(871.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(283.5645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(631.5316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1657.0034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(508.6468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(779.3835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(671.5327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1260.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(785.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1261.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(523.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.28205128205128205, 'recall': 0.11743772241992882, 'f1': 0.1658291457286432, 'number': 281}, 'P': {'precision': 0.4526143790849673, 'recall': 0.5782881002087683, 'f1': 0.5077910174152155, 'number': 479}, 'overall_precision': 0.4252400548696845, 'overall_recall': 0.40789473684210525, 'overall_f1': 0.4163868368032237, 'overall_accuracy': 0.6923038153318886}\n",
            "------------EPOCH 10---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1161.0576, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1069.5742, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1451.3264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(657.6150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(417.9578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(362.2880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(492.6979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(547.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(337.0555, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(416.1084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(381.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(688.3148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(345.3698, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(844.4409, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1049.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(686.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(419.3359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(219.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(541.6696, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(334.0874, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(540.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(484.4734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(554.7070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(234.6025, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(834.9130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1719.9758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(504.9702, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(689.0129, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(301.8728, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(228.3679, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(254.9205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(707.4907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(524.9368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(563.5538, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(961.8524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(314.8980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(695.0181, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2185.5063, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(639.5903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1147.7793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(619.6331, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1057.5383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(831.8282, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1318.5743, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(392.4448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3613861386138614, 'recall': 0.5195729537366548, 'f1': 0.42627737226277373, 'number': 281}, 'P': {'precision': 0.6377171215880894, 'recall': 0.5365344467640919, 'f1': 0.5827664399092971, 'number': 479}, 'overall_precision': 0.4993804213135068, 'overall_recall': 0.5302631578947369, 'overall_f1': 0.5143586470963625, 'overall_accuracy': 0.6967390756514289}\n",
            "------------EPOCH 11---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(584.0461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(505.7357, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(667.7006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(470.9468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(205.2601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(142.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(251.0606, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(259.4134, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(183.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(240.6320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(197.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(508.7397, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(305.4677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(659.6827, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(723.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(535.1071, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(372.5890, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(206.3696, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(677.8292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(388.7766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(754.6569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(651.0150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(862.0109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(342.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1073.9243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1931.5319, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(569.3582, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(858.6360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(279.8550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(132.1894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(140.7816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(600.6224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(268.9254, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(193.5933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(471.7024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(181.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(390.2596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1073.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(382.6835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(712.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(446.2622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(812.0344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(591.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(804.6392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(405.8732, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.29256965944272445, 'recall': 0.6725978647686833, 'f1': 0.4077669902912622, 'number': 281}, 'P': {'precision': 0.6453900709219859, 'recall': 0.18997912317327767, 'f1': 0.29354838709677417, 'number': 479}, 'overall_precision': 0.35578144853875476, 'overall_recall': 0.3684210526315789, 'overall_f1': 0.3619909502262443, 'overall_accuracy': 0.5916536464895923}\n",
            "------------EPOCH 12---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(866.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(814.7783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(808.0231, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(700.3358, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(276.9670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(158.6323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(370.6865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(467.8832, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(273.0781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(403.5190, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(381.6703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(751.8593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(345.3271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(708.8264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(764.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(656.6165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(342.5552, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(170.7418, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(292.1346, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(209.9604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(285.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(287.3998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(278.5096, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(156.4872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(612.0817, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1275.7363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(249.2477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(591.9927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(220.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(158.7943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(128.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(824.6576, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(344.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(191.4835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(830.9651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(298.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(478.6923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1514.4216, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(465.3536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(545.2052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(346.0711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(755.0503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(472.3651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(732.2786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(176.5581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.4011142061281337, 'recall': 0.5124555160142349, 'f1': 0.45, 'number': 281}, 'P': {'precision': 0.655440414507772, 'recall': 0.5281837160751566, 'f1': 0.584971098265896, 'number': 479}, 'overall_precision': 0.5328859060402684, 'overall_recall': 0.5223684210526316, 'overall_f1': 0.5275747508305648, 'overall_accuracy': 0.709440048384658}\n",
            "------------EPOCH 13---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(351.0482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(339.5661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(536.5831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(203.9974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(154.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.1105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(186.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(217.9883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(145.8526, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(141.9668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(199.5101, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(402.8726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(316.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(553.6226, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(718.7628, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(473.6432, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(322.4036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(160.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(337.9445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(228.1363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(259.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(258.6205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(276.9487, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(93.7680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(562.0756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1205.0458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(248.2354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(324.8111, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(116.4793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(72.8210, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(77.7800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(276.7760, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(114.2881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(131.8630, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(266.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(88.3110, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(142.2913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(624.2560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(194.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(382.8237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(312.6232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(419.3125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(289.5600, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(449.6277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(137.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.35805626598465473, 'recall': 0.498220640569395, 'f1': 0.4166666666666667, 'number': 281}, 'P': {'precision': 0.6067864271457086, 'recall': 0.6346555323590815, 'f1': 0.6204081632653061, 'number': 479}, 'overall_precision': 0.4977578475336323, 'overall_recall': 0.5842105263157895, 'overall_f1': 0.5375302663438256, 'overall_accuracy': 0.703492767501638}\n",
            "------------EPOCH 14---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(391.0660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(295.3109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(579.6136, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(261.4824, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(109.9411, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(77.7695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(208.2710, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(144.1395, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.8206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(77.8406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(97.8270, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(348.5570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(157.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(364.5611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(316.1490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(197.7244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(155.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(92.9632, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(226.9383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(115.9647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(138.4365, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(169.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(172.3484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(87.9065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(361.9214, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(734.9701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(88.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(290.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.3398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(59.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(167.9561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(81.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(84.6239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(184.5959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(75.0452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(112.7064, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(386.8383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(162.1037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(344.7393, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(245.8659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(233.9588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(239.1851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(286.8904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(107.0457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.39650872817955113, 'recall': 0.5658362989323843, 'f1': 0.46627565982404695, 'number': 281}, 'P': {'precision': 0.6657608695652174, 'recall': 0.511482254697286, 'f1': 0.5785123966942148, 'number': 479}, 'overall_precision': 0.5253576072821846, 'overall_recall': 0.531578947368421, 'overall_f1': 0.528449967298888, 'overall_accuracy': 0.6954790585151958}\n",
            "------------EPOCH 15---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(178.7425, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(142.7747, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(246.5602, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(91.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(96.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(59.6693, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(116.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(109.7154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.5484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.1513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(56.0349, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(190.0954, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(107.0897, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(253.9516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(197.4683, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(124.3821, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.5285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(105.7672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(65.6061, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(105.0500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(92.5220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(121.7352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(52.3332, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(211.3419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(371.8627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(72.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(144.0585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(64.7933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.9632, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(108.0052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(56.5768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.9734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(131.8871, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(58.4503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.5249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(215.2841, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(93.2462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(273.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(210.4904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(173.4755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(180.7557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(180.8310, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.8246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.4322766570605187, 'recall': 0.5338078291814946, 'f1': 0.4777070063694267, 'number': 281}, 'P': {'precision': 0.6504629629629629, 'recall': 0.5866388308977035, 'f1': 0.6169045005488473, 'number': 479}, 'overall_precision': 0.5532734274711169, 'overall_recall': 0.5671052631578948, 'overall_f1': 0.5601039636127356, 'overall_accuracy': 0.7220402197469885}\n",
            "------------EPOCH 16---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(126.1721, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.6868, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(164.9339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.9019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(76.7052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.5003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(79.8944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(72.6970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.6006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.0638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(121.8963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(75.4195, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(197.1484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(139.0229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.2719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.6031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.9740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(82.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(59.0308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(99.0700, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.1775, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(145.9157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(255.0991, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.8094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(120.1247, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.4082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.0431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(78.8910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.7569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.4650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(98.1761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(65.6114, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.0026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(162.4997, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.9908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(214.1305, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(153.6281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(126.2703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(153.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(130.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.6943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.41424802110817943, 'recall': 0.5587188612099644, 'f1': 0.4757575757575757, 'number': 281}, 'P': {'precision': 0.6541353383458647, 'recall': 0.5448851774530271, 'f1': 0.5945330296127562, 'number': 479}, 'overall_precision': 0.5372750642673522, 'overall_recall': 0.55, 'overall_f1': 0.5435630689206762, 'overall_accuracy': 0.7079784285066277}\n",
            "------------EPOCH 17---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(88.8289, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(66.8076, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(99.8549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.9667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(65.8063, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.6701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(65.9634, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.4302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.2953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.5920, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(91.8849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(56.4585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(159.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(101.4820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(63.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(48.8093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.9598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.8171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.0584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(64.7565, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.5291, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(76.8701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.2484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(118.3629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(177.7278, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.5673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(88.3967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.3713, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.9596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.7731, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(67.6415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.7583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(73.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.9204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(144.3793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.5657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(190.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.7128, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(104.5453, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(130.7719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(110.0834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.0651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.412987012987013, 'recall': 0.5658362989323843, 'f1': 0.47747747747747743, 'number': 281}, 'P': {'precision': 0.6376811594202898, 'recall': 0.5511482254697286, 'f1': 0.5912653975363942, 'number': 479}, 'overall_precision': 0.5294117647058824, 'overall_recall': 0.5565789473684211, 'overall_f1': 0.5426555484284799, 'overall_accuracy': 0.7042991784688272}\n",
            "------------EPOCH 18---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(67.9952, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.4575, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(66.4588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.8828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(58.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.2877, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.1066, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.5230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.8554, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.3508, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.9657, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(48.7950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(138.7708, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.8197, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.6735, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.3874, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.9143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.8967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.2565, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.1726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.2718, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(62.9324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.9099, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(89.2655, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(146.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(74.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.9153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.3016, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.7283, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.2581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(92.5688, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.7622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(115.0299, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.3033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(153.5089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.4111, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(89.3773, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(114.9096, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(99.5799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.39641943734015345, 'recall': 0.5516014234875445, 'f1': 0.46130952380952384, 'number': 281}, 'P': {'precision': 0.6333333333333333, 'recall': 0.5553235908141962, 'f1': 0.5917686318131257, 'number': 479}, 'overall_precision': 0.5191122071516646, 'overall_recall': 0.5539473684210526, 'overall_f1': 0.535964353914704, 'overall_accuracy': 0.7026863565344489}\n",
            "------------EPOCH 19---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(54.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.3495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.5108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.9529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.1102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.8944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.5933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.7028, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.5723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.5173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.0548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(117.8180, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(59.4135, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.5175, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.9127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.6383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.7603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.2005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(53.7619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.0450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.5727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(127.7856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.3985, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(58.8744, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.8813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.9333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.6228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.1629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.0889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(48.4828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(85.7588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.9317, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(111.6143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.1899, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(132.8860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.1678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(93.5916, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(106.6648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(94.9803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.8054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.40512820512820513, 'recall': 0.5622775800711743, 'f1': 0.47093889716840537, 'number': 281}, 'P': {'precision': 0.6276849642004774, 'recall': 0.5490605427974948, 'f1': 0.5857461024498887, 'number': 479}, 'overall_precision': 0.5203955500618047, 'overall_recall': 0.5539473684210526, 'overall_f1': 0.5366475462077755, 'overall_accuracy': 0.7023335517363036}\n",
            "------------EPOCH 20---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(43.8539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.9846, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.1691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.1520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.3617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.5415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.8394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.7917, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.9282, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.3950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(103.8454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.5860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(52.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.6611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.4369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.0904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.2684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.6272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.2689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.9088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.5448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(82.3186, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(124.5567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.9406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.9148, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.0098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.9373, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.4980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.3880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.7635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.5255, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.6197, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.1163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(127.2417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.0529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(136.2496, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(96.1816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(90.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.1929, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3963730569948187, 'recall': 0.5444839857651246, 'f1': 0.45877061469265373, 'number': 281}, 'P': {'precision': 0.6088992974238876, 'recall': 0.5427974947807933, 'f1': 0.5739514348785872, 'number': 479}, 'overall_precision': 0.5079950799507995, 'overall_recall': 0.5434210526315789, 'overall_f1': 0.5251112523839795, 'overall_accuracy': 0.6987551030694017}\n",
            "------------EPOCH 21---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(38.8890, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.2252, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.6665, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.8987, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.4670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.0994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.9949, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.8610, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.5304, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.6390, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.4788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.0715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.4513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(91.2510, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.9466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.0572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.3293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.1930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.8260, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.0018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.1555, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(72.6480, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(114.6653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(48.3896, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.3738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.1216, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.6943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.9766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5537, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.9360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.6595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.9677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(85.0950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.6972, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(106.5990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.7729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(105.9082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(78.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.9275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.41114058355437666, 'recall': 0.5516014234875445, 'f1': 0.47112462006079026, 'number': 281}, 'P': {'precision': 0.6114942528735632, 'recall': 0.5553235908141962, 'f1': 0.5820568927789934, 'number': 479}, 'overall_precision': 0.5184729064039408, 'overall_recall': 0.5539473684210526, 'overall_f1': 0.5356234096692112, 'overall_accuracy': 0.7029887606471448}\n",
            "------------EPOCH 22---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(27.2487, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.8022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.2400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.6863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.7610, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.3157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.5511, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.2423, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.1110, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.7402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.9863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.9488, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.6292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(81.6161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.5427, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.4542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.4996, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.9482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.3209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.3907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.7050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.1530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(61.0685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(124.0922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.9352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.5509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.7646, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.9228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.9714, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.0443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.5620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.6806, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.6722, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.9093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.5801, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(74.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.0270, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(128.6723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.4321, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(87.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.3420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(77.2828, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.5520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3979328165374677, 'recall': 0.5480427046263345, 'f1': 0.46107784431137727, 'number': 281}, 'P': {'precision': 0.5852534562211982, 'recall': 0.5302713987473904, 'f1': 0.556407447973713, 'number': 479}, 'overall_precision': 0.49695493300852617, 'overall_recall': 0.5368421052631579, 'overall_f1': 0.5161290322580645, 'overall_accuracy': 0.6963862708532836}\n",
            "------------EPOCH 23---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(23.0104, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.9975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.3907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.3579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.7879, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.7314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.5772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.0113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.6600, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.6429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.8442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.9211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.9162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.7894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.9574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.4154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.8320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.4656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.8568, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.9552, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(98.7561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.5835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.6605, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.2835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.4140, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.2448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.7841, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.9149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.9899, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(64.8322, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.8549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.6019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.9211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(48.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.1926, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(64.2603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.38235294117647056, 'recall': 0.5551601423487544, 'f1': 0.45283018867924524, 'number': 281}, 'P': {'precision': 0.5961995249406176, 'recall': 0.524008350730689, 'f1': 0.5577777777777777, 'number': 479}, 'overall_precision': 0.49095295536791317, 'overall_recall': 0.5355263157894737, 'overall_f1': 0.512271869100063, 'overall_accuracy': 0.6921526132755406}\n",
            "------------EPOCH 24---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(14.9180, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.6357, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.9909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.0541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.9658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.5368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.6975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.4477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.8567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.9073, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.5183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.5554, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.4795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(62.4675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.7609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.8681, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.5829, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.4815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.7840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.1586, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.7185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.5985, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.3426, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.3689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(88.2070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.8021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.0105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.1260, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.6346, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.1786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.7097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.6984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.5720, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.4847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.8852, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(61.6482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.0488, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(85.6237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.1009, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.4196, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(64.4286, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.9182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3853658536585366, 'recall': 0.5622775800711743, 'f1': 0.45730824891461647, 'number': 281}, 'P': {'precision': 0.5827338129496403, 'recall': 0.5073068893528184, 'f1': 0.5424107142857143, 'number': 479}, 'overall_precision': 0.4848851269649335, 'overall_recall': 0.5276315789473685, 'overall_f1': 0.5053560176433523, 'overall_accuracy': 0.6919510105337433}\n",
            "------------EPOCH 25---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(15.9625, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.7361, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.6863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.7894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.6004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.5979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.3813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.8016, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.2315, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.7296, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.4935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(74.1238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.4052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.7557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.9894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.8856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.5214, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.7601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.6364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.3643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(48.2643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.5456, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.2492, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.4609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.7593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.7394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.0984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.6588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.4361, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.2946, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.5147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(74.6724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.0951, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.1157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.5907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.9534, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.6394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.4270, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.9228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.8323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3787528868360277, 'recall': 0.5836298932384342, 'f1': 0.45938375350140054, 'number': 281}, 'P': {'precision': 0.5907990314769975, 'recall': 0.5093945720250522, 'f1': 0.547085201793722, 'number': 479}, 'overall_precision': 0.48226950354609927, 'overall_recall': 0.5368421052631579, 'overall_f1': 0.5080946450809465, 'overall_accuracy': 0.6795524419132101}\n",
            "------------EPOCH 26---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(13.9713, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.9545, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.6260, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.0466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.1522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.5581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.2570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.3739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.7208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.0152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.6426, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.8186, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.3964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.7226, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.4032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.8083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.1045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.6923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.2237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(85.8974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.2471, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.5912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.6924, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.2811, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.6430, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.7458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.4270, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.9045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(61.9475, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.2826, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.6760, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.2281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(61.5417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.2904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.39141414141414144, 'recall': 0.5516014234875445, 'f1': 0.4579025110782866, 'number': 281}, 'P': {'precision': 0.6098765432098765, 'recall': 0.5156576200417536, 'f1': 0.5588235294117648, 'number': 479}, 'overall_precision': 0.50187265917603, 'overall_recall': 0.5289473684210526, 'overall_f1': 0.5150544522741831, 'overall_accuracy': 0.6861045310216219}\n",
            "------------EPOCH 27---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(24.3487, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.6034, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.7354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.5586, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.0505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.8273, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.7221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.7706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.2265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.0743, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.9962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(114.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(53.6032, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.2622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.4085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.4240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.5112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(73.7084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.1683, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(81.4222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.8852, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(133.2121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(127.6009, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(73.3587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.1364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.4173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.0921, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.6145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.5401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.6624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(52.1663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(58.8857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(128.7877, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.8983, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(74.4209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(111.5605, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(268.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(111.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(87.8798, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.9704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.4336917562724014, 'recall': 0.4306049822064057, 'f1': 0.4321428571428571, 'number': 281}, 'P': {'precision': 0.6173913043478261, 'recall': 0.592901878914405, 'f1': 0.604898828541001, 'number': 479}, 'overall_precision': 0.5480378890392422, 'overall_recall': 0.5328947368421053, 'overall_f1': 0.5403602401601069, 'overall_accuracy': 0.7111536716899349}\n",
            "------------EPOCH 28---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(92.1613, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(108.2641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.6169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(97.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.1483, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.8745, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.9076, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(97.1028, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.5701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.5402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.7585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.9879, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.4970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.0478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.2225, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.4396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.5217, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.4536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.5595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.8911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.7290, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.4674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(96.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(148.4455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.7766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.9272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.6925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.3760, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.0918, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.4050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.1496, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.0727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.6424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.9413, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.5165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.6671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(127.9023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.0990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(56.9993, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.2045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.4103194103194103, 'recall': 0.594306049822064, 'f1': 0.48546511627906974, 'number': 281}, 'P': {'precision': 0.6271186440677966, 'recall': 0.5407098121085595, 'f1': 0.5807174887892377, 'number': 479}, 'overall_precision': 0.5195121951219512, 'overall_recall': 0.5605263157894737, 'overall_f1': 0.5392405063291139, 'overall_accuracy': 0.695831863313341}\n",
            "------------EPOCH 29---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(22.7437, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.6002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.3527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.2418, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.7903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.8155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.2500, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.6940, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.4137, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.4157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.3211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.1619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.8448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.8648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.6084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.5308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.7692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.8024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.0073, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.7841, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.3845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(67.1832, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(129.7501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.4070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.9735, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.2840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.8360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.5166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.3206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.9594, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.3153, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.0325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.3460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.9205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.1111, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.0002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.7838, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.8044, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.349609375, 'recall': 0.6370106761565836, 'f1': 0.45145018915510715, 'number': 281}, 'P': {'precision': 0.6812080536912751, 'recall': 0.42379958246346555, 'f1': 0.5225225225225225, 'number': 479}, 'overall_precision': 0.47160493827160493, 'overall_recall': 0.5026315789473684, 'overall_f1': 0.4866242038216561, 'overall_accuracy': 0.6664986643818356}\n",
            "------------EPOCH 30---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(19.5846, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.9433, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.8767, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.2579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.7048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.6602, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.2163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.7243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.5751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.9058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.8993, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.8235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.0249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.1570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.7338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.6744, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.3343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.5476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.1578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.6119, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.2520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.0118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(90.1859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.4474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.1780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.9294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.1107, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.5996, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.6185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.1750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.4040, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.9101, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.0019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.3037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.1754, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.1381, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(211.8555, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.4808, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.3786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3898305084745763, 'recall': 0.5729537366548043, 'f1': 0.46397694524495675, 'number': 281}, 'P': {'precision': 0.6175710594315246, 'recall': 0.4989561586638831, 'f1': 0.5519630484988454, 'number': 479}, 'overall_precision': 0.5, 'overall_recall': 0.5263157894736842, 'overall_f1': 0.5128205128205129, 'overall_accuracy': 0.7052567914923643}\n",
            "------------EPOCH 31---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(8.8407, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.3198, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.0792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.3179, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.5950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.3944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.9472, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.7573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.5171, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.3557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.8170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.5031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.8862, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.0736, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.7406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.5756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.8763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.4357, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.9985, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(109.3134, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(89.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.7272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.0899, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.5146, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.1681, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.1386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.1463, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.9682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.6860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.4019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.6910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4390, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(177.4834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.4497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.6898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.6201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.4318181818181818, 'recall': 0.5409252669039146, 'f1': 0.4802527646129542, 'number': 281}, 'P': {'precision': 0.6209016393442623, 'recall': 0.6325678496868476, 'f1': 0.626680455015512, 'number': 479}, 'overall_precision': 0.5416666666666666, 'overall_recall': 0.5986842105263158, 'overall_f1': 0.56875, 'overall_accuracy': 0.708028829192077}\n",
            "------------EPOCH 32---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(23.3477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.5683, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.9432, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.5385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.7749, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.0583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.8190, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(56.6095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.0865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.8466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.4781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.5088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.6300, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(63.7947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.0388, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.3337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.5573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.2198, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.5687, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.1457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.3585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.9062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.7189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.0234, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.7046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(87.8035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.4024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(101.1262, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.7975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.0064, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.9378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.5634, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.9359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.3239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.6311, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.9312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.8422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(62.7906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.9757, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.0274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.8386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(98.6360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.1098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(58.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.7569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.382830626450116, 'recall': 0.5871886120996441, 'f1': 0.46348314606741575, 'number': 281}, 'P': {'precision': 0.6308139534883721, 'recall': 0.453027139874739, 'f1': 0.5273390036452005, 'number': 479}, 'overall_precision': 0.49290322580645163, 'overall_recall': 0.5026315789473684, 'overall_f1': 0.4977198697068404, 'overall_accuracy': 0.6845925104581422}\n",
            "------------EPOCH 33---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(25.1401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.7088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.5435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.4874, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.6639, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1.8523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.7119, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.7968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.8104, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.3529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.0348, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.9758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.7796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.7354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.7196, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.6416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.1976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.4237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.8923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.0093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.4255, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.8366, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.4104, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.6890, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.9084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.0210, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.6967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.9947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.5375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.8486, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.6209, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.3256, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.3454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.6632, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.5443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.9374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.2013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.0441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.6002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.6964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3765586034912718, 'recall': 0.5373665480427047, 'f1': 0.44281524926686217, 'number': 281}, 'P': {'precision': 0.6095238095238096, 'recall': 0.534446764091858, 'f1': 0.5695216907675195, 'number': 479}, 'overall_precision': 0.49573690621193667, 'overall_recall': 0.5355263157894737, 'overall_f1': 0.5148640101201771, 'overall_accuracy': 0.6957310619424424}\n",
            "------------EPOCH 34---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(6.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.3758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.9089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.2296, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.9489, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.9543, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.3853, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.7106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.5115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.7930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1.8065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.7794, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.9417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.8188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.6522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.8510, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.9835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.4809, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.6919, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.3006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.1104, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.0553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.6717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.6689, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.1889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.2845, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.7882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.8929, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.3204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.6217, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.7867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.0732, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.9755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.6208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.5141, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.7766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.9979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.7697, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.36926605504587157, 'recall': 0.5729537366548043, 'f1': 0.44909344490934455, 'number': 281}, 'P': {'precision': 0.6826666666666666, 'recall': 0.534446764091858, 'f1': 0.5995316159250584, 'number': 479}, 'overall_precision': 0.5141800246609125, 'overall_recall': 0.5486842105263158, 'overall_f1': 0.530872056015277, 'overall_accuracy': 0.6962350687969356}\n",
            "------------EPOCH 35---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(13.0377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.3316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.9823, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.9159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.6622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.5455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.0189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1.7447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1.7863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.6082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.2927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.3453, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.8341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.9557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.0036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.1065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.4278, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1.3106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.9295, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1.6907, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.1736, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.2412, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.6416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.2283, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.5474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.1288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1.7753, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.0265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.5088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.6070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.4499, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.2768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.3502, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.0911, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.8232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.4896, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.7329, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.39947780678851175, 'recall': 0.5444839857651246, 'f1': 0.4608433734939759, 'number': 281}, 'P': {'precision': 0.6230769230769231, 'recall': 0.5073068893528184, 'f1': 0.5592635212888378, 'number': 479}, 'overall_precision': 0.5122897800776197, 'overall_recall': 0.5210526315789473, 'overall_f1': 0.5166340508806263, 'overall_accuracy': 0.7014263393982159}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mi7LRmfIYbR"
      },
      "source": [
        "### Rough -- Checking dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD9kGw_svbXM",
        "outputId": "b2838b14-a51e-4129-bb8c-20b274bb7a1c"
      },
      "source": [
        "\" \".join(\" mY name is \".split())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mY name is'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6-oVkplUCJh"
      },
      "source": [
        "def get_datasets():\n",
        "    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n",
        "                                                              train_sz=80,\n",
        "                                                              test_sz=20,\n",
        "                                                              mask_tokens=discourse_markers)\n",
        "    return train_dataset, valid_dataset, test_dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3qMGQ5GOzbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57323397-ef83-477b-a59d-7405173bb62c"
      },
      "source": [
        "train_dataset, _, test_dataset = get_datasets()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n",
            "2021-08-29 07:42:38.410841: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2021-08-29 07:42:38.411592: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzdpyzvKIfM8",
        "outputId": "8531f009-4bed-4ea9-daa4-d76d023d52e9"
      },
      "source": [
        "for tokenized_threads, masked_threads, comp_type_labels, _ in test_dataset:\n",
        "    tokenized_threads, masked_threads, comp_type_labels = tokenized_threads[0], masked_threads[0], comp_type_labels[0]\n",
        "    for tokenized_thread, masked_thread, comp_type_label in zip(tokenized_threads, masked_threads, comp_type_labels):\n",
        "        print(comp_type_label[:100])\n",
        "        print(tokenized_thread[:100])\n",
        "        print(tokenizer.decode(tokenized_thread[:500]))\n",
        "        start, end = 0, 0\n",
        "        prev_type = \"other\"\n",
        "        i = 0\n",
        "        while i<tokenized_thread.shape[0]:\n",
        "            if comp_type_label[i]==ac_dict[\"O\"]:\n",
        "                if prev_type==\"other\":\n",
        "                    end += 1\n",
        "                else:\n",
        "                    print(\"Component: \", tokenizer.decode(tokenized_thread[start:end+1]), \" of type: \", prev_type, tokenized_thread[start:end+1])\n",
        "                    print(\"Masked Component: \", tokenizer.decode(masked_thread[start:end+1]), \" of type: \", prev_type, masked_thread[start:end+1])\n",
        "                    start = i\n",
        "                    end = i\n",
        "                    prev_type=\"other\"\n",
        "                \n",
        "            if comp_type_label[i] in [ac_dict[\"B-C\"], ac_dict[\"B-P\"]]:\n",
        "                print(\"Component: \", tokenizer.decode(tokenized_thread[start:end+1]), \" of type: \", prev_type, tokenized_thread[start:end+1])\n",
        "                print(\"Masked Component: \", tokenizer.decode(masked_thread[start:end+1]), \" of type: \", prev_type, masked_thread[start:end+1])\n",
        "                start = i\n",
        "                end = i\n",
        "                prev_type = \"Claim\" if comp_type_label[i]==ac_dict[\"B-C\"] else \"Premise\"\n",
        "            \n",
        "            if comp_type_label[i] in [ac_dict[\"I-C\"], ac_dict[\"I-P\"]]:\n",
        "                end += 1\n",
        "            \n",
        "            i+=1\n",
        "        break\n",
        "    break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2\n",
            " 2 2 2 2 0 0 0 0 1 2 2 2 2 2 2 2 2 2 2 2 2 3 4 4 4 4]\n",
            "[    0 18814   846    35  7978     9  1901    16   145   551   350   444\n",
            " 50270 50268 50268  1121     5    94   367   688    52   348    56    80\n",
            "  1307  1061  1369    11     5   232     6   258     9    61    58  1726\n",
            "    30  3510  8941     7    22  3519     9  1901     4    22    20    78\n",
            "   145     5 11597     9  6366    81    20 21902     6     8   452     5\n",
            "  1094    23     5  4088     9    10 33937  4320    11  2201     4 50268\n",
            "   100  1819   923    84   481  1901    53     7   162  1437  8585    16\n",
            "    10   699   516   227 20203   110    78  8322   235    36  1437    22\n",
            "   270  1284 29384   328]\n",
            "<s>CMV: Freedom of speech is being taken too far [USER0] [NEWLINE] [NEWLINE] In the last few weeks we've had two huge events happen in the world, both of which were caused by matters relating to \" freedom of speech. \" The first being the hacking of Sony over The Interview, and today the shooting at the offices of a satirical magazine in Paris. [NEWLINE] I certainly value our free speech but to me there is a clear line between exercising your first amendment right (  \" President Obama sucks! \" etc ) and doing things that are known to be offensive to other cultures (  Satirical cartoons of prophets, assassinating leaders, etc ). [NEWLINE] [NEWLINE]  Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome.  [NEWLINE] [USER1] [NEWLINE] [NEWLINE] [STARTQ] Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome. [ENDQ] [NEWLINE] Sure, but that doesn't mean we condone the bully's actions and don't punish the bullies for acting. [NEWLINE] We want to live in a world without bullies, whether those bullies act on behalf of beliefs, religions, countries, or even out own governments. [NEWLINE]  Complete freedom in the expression of any idea, offensive or not, is a major element of that world. [NEWLINE] [NEWLINE]  If you want to protect the freedom to speak for any of us, you have to protect the freedom to speak for all of us. [NEWLINE] [NEWLINE] [USER0] [NEWLINE] I certainly agree with your points - I didn't mean to imply that I was only for * * some * * freedom of speech. [NEWLINE] I just think lately there's been a lot of antagonistic material being published and everyone cries freedom of speech when certain groups get upset. [NEWLINE] [NEWLINE]  Why can't America be the bigger person and say \" Ok, we won't publish certain types of material, not because we're afraid of you but because we respect your views. \"  [NEWLINE] Is that so hard? [NEWLINE] [NEWLINE] </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Component:  <s>CM  of type:  other [    0 18814]\n",
            "Masked Component:  <s>CM  of type:  other [    0 18814]\n",
            "Component:  CMV: Freedom of speech is being taken too far  of type:  Claim [18814   846    35  7978     9  1901    16   145   551   350   444]\n",
            "Masked Component:  CMV: Freedom of speech is being taken too far  of type:  Claim [18814   846    35  7978     9  1901    16   145   551   350   444]\n",
            "Component:  [USER0] [NEWLINE] [NEWLINE] In the last few weeks we've had two huge events happen in the world, both of which were caused by matters relating to \" freedom of speech. \" The first being the hacking of Sony over The Interview, and today the shooting at the offices of a satirical magazine in Paris. [NEWLINE]  of type:  other [50270 50268 50268  1121     5    94   367   688    52   348    56    80\n",
            "  1307  1061  1369    11     5   232     6   258     9    61    58  1726\n",
            "    30  3510  8941     7    22  3519     9  1901     4    22    20    78\n",
            "   145     5 11597     9  6366    81    20 21902     6     8   452     5\n",
            "  1094    23     5  4088     9    10 33937  4320    11  2201     4 50268]\n",
            "Masked Component:  [USER0] [NEWLINE] [NEWLINE] In the last few weeks we've had two huge events happen in the world, both of which were caused by matters relating to \" freedom of speech. \" The first being the hacking of Sony over The Interview, and today the shooting at the offices of a satirical magazine in Paris. [NEWLINE]  of type:  other [50270 50268 50268  1121     5    94   367   688    52   348    56    80\n",
            "  1307  1061  1369    11     5   232     6   258     9    61    58  1726\n",
            "    30  3510  8941     7    22  3519     9  1901     4    22    20    78\n",
            "   145     5 11597     9  6366    81    20 21902     6     8   452     5\n",
            "  1094    23     5  4088     9    10 33937  4320    11  2201     4 50268]\n",
            "Component:  I certainly value our free speech  of type:  Claim [ 100 1819  923   84  481 1901]\n",
            "Masked Component:  I certainly value our free speech  of type:  Claim [ 100 1819  923   84  481 1901]\n",
            "Component:   but to me   of type:  other [  53    7  162 1437]\n",
            "Masked Component:  <mask> to me   of type:  other [50264     7   162  1437]\n",
            "Component:  there is a clear line between exercising your first amendment right (   of type:  Claim [ 8585    16    10   699   516   227 20203   110    78  8322   235    36\n",
            "  1437]\n",
            "Masked Component:  there is a clear line between exercising your first amendment right (   of type:  Claim [ 8585    16    10   699   516   227 20203   110    78  8322   235    36\n",
            "  1437]\n",
            "Component:   \" President Obama sucks! \" etc  of type:  Premise [   22   270  1284 29384   328    22  4753]\n",
            "Masked Component:   \" President Obama sucks! \" etc  of type:  Premise [   22   270  1284 29384   328    22  4753]\n",
            "Component:   ) and doing things that are known to be offensive to other cultures  of type:  Claim [ 4839     8   608   383    14    32   684     7    28  2555     7    97\n",
            " 13426]\n",
            "Masked Component:   ) and doing things that are known to be offensive to other cultures  of type:  Claim [ 4839     8   608   383    14    32   684     7    28  2555     7    97\n",
            " 13426]\n",
            "Component:   (   of type:  other [  36 1437]\n",
            "Masked Component:   (   of type:  other [  36 1437]\n",
            "Component:   Satirical cartoons of prophets, assassinating leaders, etc  of type:  Premise [ 8918   853  3569 32162     9 43346     6 39257 15647   917     6  4753]\n",
            "Masked Component:   Satirical cartoons of prophets, assassinating leaders, etc  of type:  Premise [ 8918   853  3569 32162     9 43346     6 39257 15647   917     6  4753]\n",
            "Component:   ). [NEWLINE] [NEWLINE]  of type:  other [32801 50268 50268]\n",
            "Masked Component:   ). [NEWLINE] [NEWLINE]  of type:  other [32801 50268 50268]\n",
            "Component:   Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome.   of type:  Claim [ 6259    42    16    10  1099 33460   111    53   114    47   224   402\n",
            " 32726  2787     7    10 23934     8    47   120   110  8446  5836     6\n",
            "    47   197    33  5291    14  4258     4  1437]\n",
            "Masked Component:   Perhaps this is a bad analogy -<mask><mask> you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome.   of type:  Claim [ 6259    42    16    10  1099 33460   111 50264 50264    47   224   402\n",
            " 32726  2787     7    10 23934     8    47   120   110  8446  5836     6\n",
            "    47   197    33  5291    14  4258     4  1437]\n",
            "Component:  [NEWLINE] [USER1] [NEWLINE] [NEWLINE] [STARTQ] Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome. [ENDQ] [NEWLINE]  of type:  other [50268 50271 50268 50268 50265 32458    42    16    10  1099 33460   111\n",
            "    53   114    47   224   402 32726  2787     7    10 23934     8    47\n",
            "   120   110  8446  5836     6    47   197    33  5291    14  4258     4\n",
            " 50266 50268]\n",
            "Masked Component:  [NEWLINE] [USER1] [NEWLINE] [NEWLINE] [STARTQ] Perhaps this is a bad analogy -<mask><mask> you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome. [ENDQ] [NEWLINE]  of type:  other [50268 50271 50268 50268 50265 32458    42    16    10  1099 33460   111\n",
            " 50264 50264    47   224   402 32726  2787     7    10 23934     8    47\n",
            "   120   110  8446  5836     6    47   197    33  5291    14  4258     4\n",
            " 50266 50268]\n",
            "Component:  Sure  of type:  Claim [32541]\n",
            "Masked Component:  Sure  of type:  Claim [32541]\n",
            "Component:  , but   of type:  other [   6   53 1437]\n",
            "Masked Component:  ,<mask>   of type:  other [    6 50264  1437]\n",
            "Component:  that doesn't mean we condone the bully's actions and don't punish the bullies for acting  of type:  Claim [ 6025   630    75  1266    52 35005     5 23934    18  2163     8   218\n",
            "    75 15392     5 33969    13  3501]\n",
            "Masked Component:  that doesn't mean we condone the bully's actions and don't punish the bullies for acting  of type:  Claim [ 6025   630    75  1266    52 35005     5 23934    18  2163     8   218\n",
            "    75 15392     5 33969    13  3501]\n",
            "Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Masked Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Component:  We want to live in a world without bullies, whether those bullies act on behalf of beliefs, religions, countries, or even out own governments  of type:  Premise [  170   236     7   697    11    10   232   396 33969     6   549   167\n",
            " 33969  1760    15  4137     9  9734     6 24664     6   749     6    50\n",
            "   190    66   308  3233]\n",
            "Masked Component:  We want to live in a world without bullies, whether those bullies act on behalf of beliefs, religions, countries, or even out own governments  of type:  Premise [  170   236     7   697    11    10   232   396 33969     6   549   167\n",
            " 33969  1760    15  4137     9  9734     6 24664     6   749     6    50\n",
            "   190    66   308  3233]\n",
            "Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Masked Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Component:   Complete freedom in the expression of any idea, offensive or not, is a major element of that world  of type:  Premise [18337  3519    11     5  8151     9   143  1114     6  2555    50    45\n",
            "     6    16    10   538  7510     9    14   232]\n",
            "Masked Component:   Complete freedom in the expression of any idea, offensive or not, is a major element of that world  of type:  Premise [18337  3519    11     5  8151     9   143  1114     6  2555    50    45\n",
            "     6    16    10   538  7510     9    14   232]\n",
            "Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Masked Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Component:   If you want to protect the freedom to speak for any of us, you have to protect the freedom to speak for all of us  of type:  Claim [ 318   47  236    7 1744    5 3519    7 1994   13  143    9  201    6\n",
            "   47   33    7 1744    5 3519    7 1994   13   70    9  201]\n",
            "Masked Component:  <mask> you want to protect the freedom to speak for any of us, you have to protect the freedom to speak for all of us  of type:  Claim [50264    47   236     7  1744     5  3519     7  1994    13   143     9\n",
            "   201     6    47    33     7  1744     5  3519     7  1994    13    70\n",
            "     9   201]\n",
            "Component:  . [NEWLINE] [NEWLINE] [USER0] [NEWLINE]  of type:  other [    4 50268 50268 50270 50268]\n",
            "Masked Component:  . [NEWLINE] [NEWLINE] [USER0] [NEWLINE]  of type:  other [    4 50268 50268 50270 50268]\n",
            "Component:  I certainly agree with your points  of type:  Claim [ 100 1819 2854   19  110  332]\n",
            "Masked Component:  I certainly agree with your points  of type:  Claim [ 100 1819 2854   19  110  332]\n",
            "Component:   -   of type:  other [ 111 1437]\n",
            "Masked Component:   -   of type:  other [ 111 1437]\n",
            "Component:  I didn't mean to imply that I was only for * * some * * freedom of speech  of type:  Claim [  100   399    75  1266     7 25696    14    38    21   129    13  1009\n",
            "  1009   103  1009  1009  3519     9  1901]\n",
            "Masked Component:  I didn't mean to imply that I was only for * * some * * freedom of speech  of type:  Claim [  100   399    75  1266     7 25696    14    38    21   129    13  1009\n",
            "  1009   103  1009  1009  3519     9  1901]\n",
            "Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Masked Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Component:  I just think lately there's been a lot of antagonistic material being published and everyone cries freedom of speech when certain groups get upset  of type:  Claim [  100    95   206 12056    89    18    57    10   319     9 32726  5580\n",
            "  1468   145  1027     8   961 25355  3519     9  1901    77  1402  1134\n",
            "   120  4904]\n",
            "Masked Component:  I just think lately there's been a lot of antagonistic material being published and everyone cries freedom of speech<mask> certain groups get upset  of type:  Claim [  100    95   206 12056    89    18    57    10   319     9 32726  5580\n",
            "  1468   145  1027     8   961 25355  3519     9  1901 50264  1402  1134\n",
            "   120  4904]\n",
            "Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Masked Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Component:   Why can't America be the bigger person and say \" Ok, we won't publish certain types of material, not because we're afraid of you but because we respect your views. \"   of type:  Premise [ 2612    64    75   730    28     5  2671   621     8   224    22  5148\n",
            "     6    52   351    75 10732  1402  3505     9  1468     6    45   142\n",
            "    52   214  6023     9    47    53   142    52  2098   110  2728     4\n",
            "    22  1437]\n",
            "Masked Component:  <mask> can't America be the bigger person and say \" Ok, we won't publish certain types of material, not<mask> we're afraid of you<mask><mask> we respect your views. \"   of type:  Premise [50264    64    75   730    28     5  2671   621     8   224    22  5148\n",
            "     6    52   351    75 10732  1402  3505     9  1468     6    45 50264\n",
            "    52   214  6023     9    47 50264 50264    52  2098   110  2728     4\n",
            "    22  1437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZnb1Nz-MX4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2601bebd-3989-40a5-af7d-91d578651823"
      },
      "source": [
        "import re\n",
        "re.sub(r\"\\s*</claim>([^\\s])\", r\"</claim> \\1\", \"<claim>my name is </claim>jeevesh.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<claim>my name is</claim> jeevesh.'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UVJb5jy178"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}