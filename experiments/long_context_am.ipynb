{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "long_context_am.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbBNTbptLTDKf1X0ulLzRM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeevesh8/arg_mining/blob/main/experiments/long_context_am.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOGdooHmfgd-"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GPY8HXWtkyE"
      },
      "source": [
        "%%capture\n",
        "#if running on colab, install below 4\n",
        "#!git clone https://github.com/Jeevesh8/arg_mining\n",
        "#!pip install transformers\n",
        "#!pip install seqeval datasets allennlp\n",
        "#!pip install flax\n",
        "\n",
        "#if connected to local runtime, run the next command too\n",
        "#pip install bs4 tensorflow torch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs8QzJCbx9lO"
      },
      "source": [
        "\n",
        "\n",
        "*   Update ``arg_mining/datasets/cmv_modes/configs.py`` as per your requirements, all experiments considered till now, set ``batch_size`` to 2, and all other variables with their default value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_glbajGinKG4"
      },
      "source": [
        "#Run to ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pCBwYZjfkHw"
      },
      "source": [
        "### Load Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkKUqJo4e_Rc"
      },
      "source": [
        "from datasets import load_metric\n",
        "metric = load_metric('seqeval')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35kJb8EE0Fm-"
      },
      "source": [
        "### Krippendorff's Alpha Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik1XOXUu0FOw"
      },
      "source": [
        "from typing import List, Tuple\n",
        "import re\n",
        "\n",
        "class krip_alpha():\n",
        "    \"\"\"A module for computing sentence level Krippendorff's Alpha,\n",
        "    for argumentative components  annotated at the token level. Must use\n",
        "    labels [\"B-C\", \"B-P\"].\n",
        "    \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"See self.compute_metric() for what each of these data actually mean.\n",
        "        \"\"\"\n",
        "        self.pred_has_claim = 0\n",
        "        self.ref_has_claim = 0\n",
        "        self.pred_has_premise = 0\n",
        "        self.ref_has_premise = 0\n",
        "        \n",
        "        self.claim_wise_agreement = 0\n",
        "        self.premise_wise_agreement = 0\n",
        "        \n",
        "        self.claim_wise_disagreement = 0\n",
        "        self.premise_wise_disagreement = 0\n",
        "    \n",
        "        self.total_sentences = 0\n",
        "        \n",
        "        self.has_both_ref = 0\n",
        "        self.has_both_pred = 0\n",
        "        self.has_none_ref = 0\n",
        "        self.has_none_pred = 0\n",
        "\n",
        "    def preprocess(self, threads: List[List[int]]) -> List[List[List[int]]]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            threads:    A list of all threads in a batch. A thread is a list of \n",
        "                        integers corresponding to token_ids of the tokens in the \n",
        "                        thread.\n",
        "        Returns:\n",
        "            A List with all the threads, where each thread now consists of \n",
        "            sentence lists. Where, a sentence list in a thread list is the list \n",
        "            of token_ids corresponding to a sentence in a thread. \n",
        "        \"\"\"\n",
        "        threads_lis = []\n",
        "\n",
        "        for i, thread in enumerate(threads):\n",
        "            sentence = []\n",
        "            threads_lis.append([])\n",
        "            for j, token_id in enumerate(thread):\n",
        "                if token_id==tokenizer.pad_token_id:\n",
        "                    break\n",
        "                \n",
        "                sentence.append(token_id)\n",
        "                token = tokenizer.convert_ids_to_tokens(token_id)\n",
        "                #print(\"appended token:\", token)\n",
        "\n",
        "                next_token = 'None' if j==len(thread) else tokenizer.convert_ids_to_tokens(thread[j+1])\n",
        "\n",
        "                if (token.count('.')+token.count('?')+token.count('!')>=1 and \n",
        "                    next_token.count('.')+next_token.count('?')+next_token.count('!')==0):\n",
        "\n",
        "                    threads_lis[i].append(sentence)\n",
        "                    #print(\"Sample sentence: \", tokenizer.decode(sentence))\n",
        "                    sentence = []\n",
        "                \n",
        "                elif re.findall(r\"\\[USER\\d+\\]|\\[UNU\\]\", token)!=[]:\n",
        "                    prev_part = tokenizer.decode(sentence[:-1])[1:-1]\n",
        "                    if re.search(r'[a-zA-Z]', prev_part) is not None:\n",
        "                        threads_lis[i].append(sentence[:-1])\n",
        "                        #print(\"Sample sentence just befor user token:\", tokenizer.decode(sentence[:-1]))\n",
        "                        sentence = [sentence[-1]]\n",
        "                    else:\n",
        "                        k=len(sentence)-2\n",
        "                        while k>=0 and sentence[k]==tokenizer.convert_tokens_to_ids('Ġ'):\n",
        "                            k-=1\n",
        "                        sentence = sentence[k+1:]\n",
        "                        threads_lis[i][-1] += sentence[:k]\n",
        "                        #print(\"Sample sentence just befor user token:\", tokenizer.decode(threads_lis[i][-1]))\n",
        "                \n",
        "            has_rem_token = False\n",
        "            for elem in sentence:\n",
        "                if (elem!=tokenizer.convert_tokens_to_ids('Ġ') and\n",
        "                    elem!=tokenizer.eos_token_id):\n",
        "                    has_rem_token = True\n",
        "                    break\n",
        "            \n",
        "            if has_rem_token:\n",
        "                threads_lis[i].append(sentence)\n",
        "                #print(\"Sample sentence at end of thread: \", tokenizer.decode(sentence))\n",
        "                sentence = []\n",
        "\n",
        "        return threads_lis\n",
        "\n",
        "    def get_sentence_wise_preds(self, threads: List[List[List[int]]], \n",
        "                                      predictions: List[List[str]]) -> List[List[List[str]]]:\n",
        "        \"\"\"Splits the prediction corresponding to each thread, into predictions\n",
        "        for each sentence in the corresponding thread in \"threads\" list.\n",
        "        Args:\n",
        "            threads:      A list of threads, where each thread consists of further \n",
        "                          lists corresponding to the various sentences in the\n",
        "                          thread. [As output by self.preprocess()]\n",
        "            predictions:  A list of predictions for each thread, in the threads\n",
        "                          list. Each prediciton consists of a list of componenet \n",
        "                          types corresponding to each token in a thread.\n",
        "        Returns:\n",
        "            The predictions list, with each prediction split into predictions \n",
        "            corresponding to the sentences in the corresponding thread specified\n",
        "            in the threads list. \n",
        "        \"\"\"\n",
        "        sentence_wise_preds = []\n",
        "        for i, thread in enumerate(threads):\n",
        "            next_sentence_beg = 0\n",
        "            sentence_wise_preds.append([])\n",
        "            for sentence in thread:\n",
        "                sentence_wise_preds[i].append(\n",
        "                    predictions[i][next_sentence_beg:next_sentence_beg+len(sentence)])\n",
        "                next_sentence_beg += len(sentence)\n",
        "        return sentence_wise_preds\n",
        "    \n",
        "    def update_state(self, pred_sentence: List[str], ref_sentence: List[str]) -> None:\n",
        "        \"\"\"Updates the various information maintained for the computation of\n",
        "        Krippendorff's alpha, based on the predictions(pred_sentence) and \n",
        "        references(ref_sentence) provided for a particular sentence, in some \n",
        "        thread.\n",
        "        \"\"\"\n",
        "        self.total_sentences += 1\n",
        "        \n",
        "        if 'B-C' in pred_sentence:\n",
        "            self.pred_has_claim += 1\n",
        "            if 'B-C' in ref_sentence:\n",
        "                self.ref_has_claim += 1\n",
        "                self.claim_wise_agreement += 1\n",
        "            else:\n",
        "                self.claim_wise_disagreement += 1\n",
        "            \n",
        "        elif 'B-C' in ref_sentence:\n",
        "            self.ref_has_claim += 1\n",
        "            self.claim_wise_disagreement += 1\n",
        "        \n",
        "        else:\n",
        "            self.claim_wise_agreement += 1\n",
        "        \n",
        "        if 'B-P' in pred_sentence:\n",
        "            self.pred_has_premise += 1\n",
        "            if 'B-P' in ref_sentence:\n",
        "                self.ref_has_premise += 1\n",
        "                self.premise_wise_agreement += 1\n",
        "            else:\n",
        "                self.premise_wise_disagreement += 1\n",
        "\n",
        "        elif 'B-P' in ref_sentence:\n",
        "            self.ref_has_premise += 1\n",
        "            self.premise_wise_disagreement += 1\n",
        "        \n",
        "        else:\n",
        "            self.premise_wise_agreement += 1\n",
        "        \n",
        "        if 'B-C' in pred_sentence and 'B-P' in pred_sentence:\n",
        "            self.has_both_pred += 1\n",
        "        \n",
        "        if 'B-C' in ref_sentence and 'B-P' in ref_sentence:\n",
        "            self.has_both_ref += 1\n",
        "        \n",
        "        if 'B-C' not in pred_sentence and 'B-P' not in pred_sentence:\n",
        "            self.has_none_pred += 1\n",
        "        \n",
        "        if 'B-C' not in ref_sentence and 'B-P' not in ref_sentence:\n",
        "            self.has_none_ref += 1\n",
        "        return\n",
        "\n",
        "    def add_batch(self, predictions: List[List[str]], \n",
        "                  references: List[List[str]], \n",
        "                  tokenized_threads: List[List[int]]) -> None:\n",
        "        \"\"\"Add a batch of predictions and references for the computation of \n",
        "        Krippendorff's alpha.\n",
        "        Args:\n",
        "            predictions:      A list of predictions for each thread, in the \n",
        "                              threads list. Each prediciton consists of a list \n",
        "                              of component types corresponding to each token in \n",
        "                              a thread.\n",
        "            references:       Same structure as predictions, but consisting of \n",
        "                              acutal gold labels, instead of predicted ones.\n",
        "            tokenized_thread: A list of all threads in a batch. A thread is a \n",
        "                              list of integers corresponding to token_ids of the\n",
        "                              tokens in the thread.\n",
        "        \"\"\"\n",
        "        threads = self.preprocess(tokenized_threads)\n",
        "        \n",
        "        sentence_wise_preds = self.get_sentence_wise_preds(threads, predictions)\n",
        "        sentence_wise_refs = self.get_sentence_wise_preds(threads, references)\n",
        "\n",
        "        for pred_thread, ref_thread in zip(sentence_wise_preds, sentence_wise_refs):\n",
        "            for pred_sentence, ref_sentence in zip(pred_thread, ref_thread):\n",
        "                self.update_state(pred_sentence, ref_sentence)\n",
        "\n",
        "    def compute(self, print_additional: bool=True) -> None:\n",
        "        \"\"\"Prints out the metric, for the batched added till now. And then \n",
        "        resets all data being maintained by the metric. \n",
        "        Args:\n",
        "            print_additional:   If True, will print all the data being \n",
        "                                maintained instead of just the Krippendorff's \n",
        "                                alphas for claims and premises.\n",
        "        \"\"\"\n",
        "        print(\"Sentence level Krippendorff's alpha for Claims: \", 1-(self.claim_wise_disagreement/(self.claim_wise_agreement+self.claim_wise_disagreement))/0.5)\n",
        "        print(\"Sentence level Krippendorff's alpha for Premises: \", 1-(self.premise_wise_disagreement/(self.premise_wise_agreement+self.premise_wise_disagreement))/0.5)\n",
        "        \n",
        "        if print_additional:\n",
        "            print(\"Additional attributes: \")\n",
        "            print(\"\\tTotal Sentences:\", self.total_sentences)\n",
        "            print(\"\\tPrediction setences having claims:\", self.pred_has_claim)\n",
        "            print(\"\\tPrediction sentences having premises:\", self.pred_has_premise)\n",
        "            print(\"\\tReference setences having claims:\", self.ref_has_claim)\n",
        "            print(\"\\tReference sentences having premises:\", self.ref_has_premise)\n",
        "            print(\"\\n\")\n",
        "            print(\"\\tPrediction Sentence having both claim and premise:\", self.has_both_pred)\n",
        "            print(\"\\tPrediction Sentence having neither claim nor premise:\", self.has_none_pred)\n",
        "            print(\"\\tReference Sentence having both claim and premise:\", self.has_both_ref)\n",
        "            print(\"\\tReference Sentence having neither claim nor premise:\", self.has_none_ref)\n",
        "            print(\"\\n\")\n",
        "            print(\"\\tSentences having claim in both reference and prediction:\", self.claim_wise_agreement)\n",
        "            print(\"\\tSentences having claim in only one of reference or prediction:\", self.claim_wise_disagreement)\n",
        "            print(\"\\tSentences having premise in both reference and prediction:\", self.premise_wise_agreement)\n",
        "            print(\"\\tSentences having premise in only one of reference or prediction:\", self.premise_wise_disagreement)\n",
        "        self.__init__()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYRNv0wBWtFd"
      },
      "source": [
        "metric = krip_alpha()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjf6BxMkfm3R"
      },
      "source": [
        "### Define & Load Tokenizer, Model, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wcsqmllnfRB"
      },
      "source": [
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45DeXxCDS_id",
        "outputId": "b061a062-f780-47e7-d8b3-bea061e735b6"
      },
      "source": [
        "device"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHRkCQOZu6HS"
      },
      "source": [
        "model_version = 'allenai/longformer-base-4096'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6cB-7M9t0HP"
      },
      "source": [
        "%%capture\n",
        "from transformers import LongformerTokenizer, AutoModel\n",
        "tokenizer = LongformerTokenizer.from_pretrained(model_version)\n",
        "transformer_model = AutoModel.from_pretrained(model_version).to(device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ajTzrbzkwbT"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "#Extend Token Type Embeddings\n",
        "def resize_token_type_embeddings(transformer_model, new_size):\n",
        "    old_embeddings = transformer_model.embeddings.token_type_embeddings.weight\n",
        "    old_size, hidden_dim = old_embeddings.shape\n",
        "    transformer_model.embeddings.token_type_embeddings = nn.Embedding(new_size, hidden_dim, device=transformer_model.device)\n",
        "    with torch.no_grad():\n",
        "        transformer_model.embeddings.token_type_embeddings.weight[:old_size] = old_embeddings\n",
        "\n",
        "#resize_token_type_embeddings(transformer_model, 2)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p6dGA83cGVS"
      },
      "source": [
        "with open('./Discourse_Markers.txt') as f:\n",
        "    discourse_markers = [dm.strip() for dm in f.readlines()]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTCeCgbLxVyQ"
      },
      "source": [
        "%%capture\n",
        "from arg_mining.datasets.cmv_modes import load_dataset, data_config\n",
        "\n",
        "tokenizer.add_tokens(data_config[\"special_tokens\"])\n",
        "\n",
        "transformer_model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def get_datasets():\n",
        "    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n",
        "                                                              train_sz=80,\n",
        "                                                              test_sz=20,\n",
        "                                                              mask_tokens=discourse_markers)\n",
        "    return train_dataset, valid_dataset, test_dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi_8gVbufzoX"
      },
      "source": [
        "### Define layers for a Linear-Chain-CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seBwkZdByesM"
      },
      "source": [
        "from allennlp.modules.conditional_random_field import ConditionalRandomField as crf\n",
        "\n",
        "ac_dict = data_config[\"arg_components\"]\n",
        "\n",
        "allowed_transitions =([(ac_dict[\"B-C\"], ac_dict[\"I-C\"]), \n",
        "                       (ac_dict[\"B-P\"], ac_dict[\"I-P\"])] + \n",
        "                      [(ac_dict[\"I-C\"], ac_dict[ct]) \n",
        "                        for ct in [\"I-C\", \"B-C\", \"B-P\", \"O\"]] +\n",
        "                      [(ac_dict[\"I-P\"], ac_dict[ct]) \n",
        "                        for ct in [\"I-P\", \"B-C\", \"B-P\", \"O\"]] +\n",
        "                      [(ac_dict[\"O\"], ac_dict[ct]) \n",
        "                        for ct in [\"O\", \"B-C\", \"B-P\"]])\n",
        "                    \n",
        "linear_layer = nn.Linear(transformer_model.config.hidden_size,\n",
        "                         len(ac_dict)).to(device)\n",
        "\n",
        "crf_layer = crf(num_tags=len(ac_dict),\n",
        "                constraints=allowed_transitions,\n",
        "                include_start_end_transitions=False).to(device)\n",
        "\n",
        "cross_entropy_layer = nn.CrossEntropyLoss(weight=torch.log(torch.tensor([3.3102, 61.4809, 3.6832, 49.6827, 2.5639], \n",
        "                                                                        device=device)), reduction='none')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUicsK33f9d7"
      },
      "source": [
        "### Global Attention Mask Utility for Longformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOSo7p2I5mOi"
      },
      "source": [
        "import numpy as np\n",
        "from threading import Lock\n",
        "\n",
        "def get_global_attention_mask(tokenized_threads: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Returns an attention mask, with 1 where there are [USER{i}] tokens and \n",
        "    0 elsewhere.\n",
        "    \"\"\"\n",
        "    mask = np.zeros_like(tokenized_threads)\n",
        "    for user_token in [\"UNU\"]+[f\"[USER{i}]\" for i in range(data_config[\"max_users\"])]:\n",
        "        user_token_id = tokenizer.encode(user_token)[1:-1]\n",
        "        mask = np.where(tokenized_threads==user_token_id, 1, mask)\n",
        "    return np.array(mask, dtype=bool)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bp4PLQihf5CT"
      },
      "source": [
        "### Loss and Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL3u8eH1rjZe"
      },
      "source": [
        "from typing import Tuple"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuJ5aryW9tUC"
      },
      "source": [
        "def compute(batch: Tuple[torch.Tensor, torch.Tensor, torch.Tensor],\n",
        "            preds: bool=False, cross_entropy: bool=True):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        batch:  A tuple having tokenized thread of shape [batch_size, seq_len],\n",
        "                component type labels of shape [batch_size, seq_len], and a global\n",
        "                attention mask for Longformer, of the same shape.\n",
        "        \n",
        "        preds:  If True, returns a List(of batch_size size) of Tuples of form \n",
        "                (tag_sequence, viterbi_score) where the tag_sequence is the \n",
        "                viterbi-decoded sequence, for the corresponding sample in the batch.\n",
        "        \n",
        "        cross_entropy:  This argument will only be used if preds=False, i.e., if \n",
        "                        loss is being calculated. If True, then cross entropy loss\n",
        "                        will also be added to the output loss.\n",
        "    \n",
        "    Returns:\n",
        "        Either the predicted sequences with their scores for each element in the batch\n",
        "        (if preds is True), or the loss value summed over all elements of the batch\n",
        "        (if preds is False).\n",
        "    \"\"\"\n",
        "    tokenized_threads, token_type_ids, comp_type_labels, global_attention_mask = batch\n",
        "    \n",
        "    pad_mask = torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0)\n",
        "    \n",
        "    logits = linear_layer(transformer_model(input_ids=tokenized_threads,\n",
        "                               attention_mask=pad_mask,\n",
        "                               global_attention_mask=global_attention_mask).last_hidden_state)\n",
        "    \n",
        "    if preds:\n",
        "        return crf_layer.viterbi_tags(logits, pad_mask)\n",
        "    \n",
        "    log_likelihood = crf_layer(logits, comp_type_labels, pad_mask)\n",
        "    \n",
        "    if cross_entropy:\n",
        "        logits = logits.reshape(-1, logits.shape[-1])\n",
        "        \n",
        "        pad_mask, comp_type_labels = pad_mask.reshape(-1), comp_type_labels.reshape(-1)\n",
        "        \n",
        "        ce_loss = torch.sum(pad_mask*cross_entropy_layer(logits, comp_type_labels))\n",
        "        \n",
        "        return ce_loss - log_likelihood\n",
        "\n",
        "    return -log_likelihood"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot6lkPCsgEY4"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-yfpzEMBGra"
      },
      "source": [
        "from itertools import chain\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(params = chain(transformer_model.parameters(),\n",
        "                                      linear_layer.parameters(),\n",
        "                                      crf_layer.parameters()),\n",
        "                       lr = 2e-5,)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdSWnkO8gLD6"
      },
      "source": [
        "### Training And Evaluation Loops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTNaP3kLaN2X"
      },
      "source": [
        "def train(dataset):\n",
        "    accumulate_over = 4\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, (tokenized_threads, masked_threads, comp_type_labels, _ ) in enumerate(dataset):\n",
        "        global_attention_mask = torch.tensor(get_global_attention_mask(tokenized_threads),\n",
        "                                             device=device, dtype=torch.int32)\n",
        "        \n",
        "        #Remove Device Axis and cast to PyTorch tensor\n",
        "        tokenized_threads = torch.tensor(np.squeeze(tokenized_threads, axis=0), \n",
        "                                         device=device)\n",
        "        masked_threads = torch.tensor(np.squeeze(masked_threads, axis=0), \n",
        "                                      device=device)\n",
        "        comp_type_labels = torch.tensor(np.squeeze(comp_type_labels, axis=0), \n",
        "                                        device=device, dtype=torch.long)\n",
        "        \n",
        "        global_attention_mask = torch.squeeze(global_attention_mask, dim=0)\n",
        "        \n",
        "        loss = compute((masked_threads,\n",
        "                        torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n",
        "                        comp_type_labels, \n",
        "                        global_attention_mask))/data_config[\"batch_size\"]\n",
        "        \n",
        "        print(\"Loss: \", loss)\n",
        "        loss.backward()\n",
        "        \n",
        "        if i%accumulate_over==accumulate_over-1:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "    \n",
        "    optimizer.step()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeHJiT0sjXid"
      },
      "source": [
        "#transformer_model.config.type_vocab_size = 2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7BpSI83cU24"
      },
      "source": [
        "def evaluate(dataset, metric):\n",
        "    \n",
        "    int_to_labels = {v:k for k, v in ac_dict.items()}\n",
        "    \n",
        "    for tokenized_threads, masked_threads, comp_type_labels, _ in dataset:\n",
        "        \n",
        "        global_attention_mask = torch.tensor(get_global_attention_mask(tokenized_threads), \n",
        "                                             device=device)\n",
        "        \n",
        "        #Remove Device Axis and cast to PyTorch tensor\n",
        "        tokenized_threads = torch.tensor(np.squeeze(tokenized_threads, axis=0),\n",
        "                                        device=device)\n",
        "        masked_threads = torch.tensor(np.squeeze(masked_threads, axis=0),\n",
        "                                     device=device)\n",
        "        comp_type_labels = torch.tensor(np.squeeze(comp_type_labels, axis=0),\n",
        "                                        device=device)\n",
        "        global_attention_mask = torch.squeeze(global_attention_mask, dim=0)\n",
        "        \n",
        "        preds = compute((masked_threads,\n",
        "                         torch.where(masked_threads==tokenizer.mask_token_id, 1, 0), \n",
        "                         comp_type_labels,\n",
        "                         global_attention_mask),\n",
        "                        preds=True)\n",
        "        \n",
        "        lengths = torch.sum(torch.where(tokenized_threads!=tokenizer.pad_token_id, 1, 0), \n",
        "                            axis=-1)\n",
        "        \n",
        "        preds = [ [int_to_labels[pred] for pred in pred[0][:lengths[i]]]\n",
        "                  for i, pred in enumerate(preds)\n",
        "                ]\n",
        "        \n",
        "        refs = [ [int_to_labels[ref] for ref in labels[:lengths[i]]]\n",
        "                 for i, labels in enumerate(comp_type_labels.cpu().tolist())\n",
        "               ]\n",
        "        \n",
        "        metric.add_batch(predictions=preds, \n",
        "                         references=refs,)\n",
        "                         #tokenized_threads=tokenized_threads.cpu().tolist())\n",
        "    \n",
        "    print(metric.compute())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZV6rnIQgOYA"
      },
      "source": [
        "### Final Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O2O5qCufGwA"
      },
      "source": [
        "n_epochs = 35"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30xcK9sOgX44",
        "outputId": "69455ab3-7631-4c06-f170-e5bc5abfd327"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    print(f\"------------EPOCH {epoch+1}---------------\")\n",
        "    train_dataset, _, test_dataset = get_datasets()\n",
        "    train(train_dataset)\n",
        "    evaluate(test_dataset, metric)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------EPOCH 1---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(13117.6152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12949.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13218.9414, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12896.9102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12247.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12282.8320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12272.0225, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12272.4932, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11430.6055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11549.7256, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11667.9668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11726.8281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10854.3418, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11128.9648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11364.6660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11042.8457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10130.3857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9826.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10106.6621, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9989.9238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6890.4219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6557.6094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7154.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6637.6729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5301.9414, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7683.8208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5141.7515, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5117.0957, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2320.6768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2112.5024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2023.2351, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3830.5435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2369.5674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2308.6565, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3323.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1255.5780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2997.5571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5891.7207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1892.5037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3923.5706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2511.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3557.7073, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2709.4868, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4270.2002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1952.4863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 281}, 'P': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 479}, 'overall_precision': 0.0, 'overall_recall': 0.0, 'overall_f1': 0.0, 'overall_accuracy': 0.33198931505468476}\n",
            "------------EPOCH 2---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(2856.7793, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2224.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2893.7578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2464.3601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1699.7513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1735.3311, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2077.8076, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2430.7622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1712.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1891.6741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2033.6946, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2760.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2256.7847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3356.9458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3531.4150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2394.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2039.8572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(942.9084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1694.3024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1210.2585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2025.8967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1446.7188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2180.2405, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1513.0498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3469.6562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6007.0264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3305.1592, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3365.5322, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1445.0277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1270.4160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1184.4170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2812.4204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1840.9187, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1740.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2675.3635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(879.4437, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2663.6370, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5009.8213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1487.8062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3158.4543, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1967.9780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3098.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2578.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3799.9658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1653.3370, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.07692307692307693, 'recall': 0.014234875444839857, 'f1': 0.024024024024024024, 'number': 281}, 'P': {'precision': 0.06315789473684211, 'recall': 0.025052192066805846, 'f1': 0.035874439461883414, 'number': 479}, 'overall_precision': 0.06611570247933884, 'overall_recall': 0.021052631578947368, 'overall_f1': 0.03193612774451098, 'overall_accuracy': 0.49720276195756263}\n",
            "------------EPOCH 3---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(2317.8010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1845.2816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2450.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2125.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1638.3812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1599.7896, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1863.4485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1924.5803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1311.5476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1446.9081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1630.5770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2416.2495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1909.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2905.3025, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2991.7192, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1913.6086, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1758.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(798.4711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1421.6674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(942.0042, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1729.8245, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1174.3818, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1782.4540, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1282.4812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2914.8174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5324.8906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3004.9631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3135.7317, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1258.6232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1156.6730, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1093.0085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2475.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1644.5359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1591.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2463.8201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(804.6100, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2528.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4720.8188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1338.9319, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2865.9080, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1772.6849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2831.2205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2462.6074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3593.2246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1515.4685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.11235955056179775, 'recall': 0.03558718861209965, 'f1': 0.054054054054054064, 'number': 281}, 'P': {'precision': 0.13125, 'recall': 0.1315240083507307, 'f1': 0.1313868613138686, 'number': 479}, 'overall_precision': 0.1282952548330404, 'overall_recall': 0.09605263157894736, 'overall_f1': 0.10985703536493605, 'overall_accuracy': 0.5544075399425432}\n",
            "------------EPOCH 4---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(2080.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1663.6643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2198.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1972.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1479.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1476.2948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1694.4275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1750.6860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1220.0443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1334.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1471.2856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2127.5281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1734.7642, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2717.3584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2732.9756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1801.1455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1638.8091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(750.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1330.8486, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(912.7996, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1571.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1133.9359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1681.8121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1149.0496, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2680.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4853.4741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2640.1179, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2792.2410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1153.8650, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1090.3403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1010.7384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2254.6912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1462.1343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1422.7383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2287.1074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(736.4840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2343.2717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4422.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1248.6194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2611.3628, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1637.5519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2668.5522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2341.1489, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3391.8560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1411.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.12759643916913946, 'recall': 0.15302491103202848, 'f1': 0.13915857605177992, 'number': 281}, 'P': {'precision': 0.37986270022883295, 'recall': 0.3465553235908142, 'f1': 0.3624454148471616, 'number': 479}, 'overall_precision': 0.27002583979328165, 'overall_recall': 0.275, 'overall_f1': 0.27249022164276404, 'overall_accuracy': 0.5938712766493625}\n",
            "------------EPOCH 5---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1847.1061, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1498.7139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1981.4364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1854.7665, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1418.0452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1376.7603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1565.4910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1528.9915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1047.7728, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1158.2697, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1249.7371, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1929.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1563.1644, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2492.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2470.2539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1638.8910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1524.5627, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(683.4458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1205.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(809.1610, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1421.1501, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1019.3491, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1521.9540, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1041.7881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2418.6980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4479.7158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2354.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2549.5049, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1042.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1042.5781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(943.7205, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2086.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1305.0542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1231.6118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2098.7202, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(671.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2055.4006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3991.8970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1133.7583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2317.2422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1539.4692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2487.6953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2031.8906, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3080.6318, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1314.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.1474820143884892, 'recall': 0.14590747330960854, 'f1': 0.14669051878354203, 'number': 281}, 'P': {'precision': 0.43137254901960786, 'recall': 0.4133611691022965, 'f1': 0.4221748400852879, 'number': 479}, 'overall_precision': 0.3242876526458616, 'overall_recall': 0.3144736842105263, 'overall_f1': 0.31930527722110885, 'overall_accuracy': 0.6318733934781513}\n",
            "------------EPOCH 6---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1728.7406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1443.5238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1871.8125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1714.3975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1312.3748, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1258.9849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1420.7095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1395.3008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(930.9818, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1052.3323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1117.7980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1751.6011, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1284.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2144.6631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2270.9380, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1484.0361, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1398.5259, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(612.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1115.2028, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(730.9391, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1288.4675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(878.6385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1354.8083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(908.5420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2173.5940, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4107.4082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2041.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2269.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(927.1779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(986.5856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(872.0159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1945.0656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1174.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1078.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1947.1772, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(611.8867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1760.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3575.5762, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(985.9324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2049.1069, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1393.5900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2273.5530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1771.4519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2769.9436, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1180.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.16176470588235295, 'recall': 0.15658362989323843, 'f1': 0.15913200723327303, 'number': 281}, 'P': {'precision': 0.4487704918032787, 'recall': 0.4572025052192067, 'f1': 0.45294725956566695, 'number': 479}, 'overall_precision': 0.3460526315789474, 'overall_recall': 0.3460526315789474, 'overall_f1': 0.3460526315789474, 'overall_accuracy': 0.6431127463333501}\n",
            "------------EPOCH 7---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1546.8727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1320.0017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1722.4164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1452.6179, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1092.4360, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1044.2476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1241.4199, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1226.8973, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(827.0464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(926.5648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(994.1361, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1554.8108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(979.7107, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1820.8173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2053.0093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1304.9677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1234.7822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(556.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1004.8419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(630.6216, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1127.4192, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(773.4800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1173.3275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(773.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1891.2671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3705.3220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1682.3987, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1915.2704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(814.4440, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(870.7467, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(768.0126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1773.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1055.4194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(882.5922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1725.6973, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(548.9727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1555.0376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3204.8916, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(838.5280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1785.9636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1216.4368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2082.2637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1542.5950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2492.8660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1069.9520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.11357340720221606, 'recall': 0.14590747330960854, 'f1': 0.1277258566978193, 'number': 281}, 'P': {'precision': 0.48623853211009177, 'recall': 0.44258872651356995, 'f1': 0.46338797814207655, 'number': 479}, 'overall_precision': 0.3174404015056462, 'overall_recall': 0.33289473684210524, 'overall_f1': 0.32498394348105336, 'overall_accuracy': 0.6402399072627388}\n",
            "------------EPOCH 8---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1384.1636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1252.7092, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1547.6138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1198.2639, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(842.1431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(817.9219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1080.3933, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1067.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(736.7085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(789.5645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(789.4396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1339.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(760.7285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1575.9261, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1829.4283, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1149.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1093.5741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(500.8572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(935.9902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(551.8480, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(960.4614, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(693.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1016.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(629.1612, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1624.2489, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3318.9036, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1378.6248, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1484.0408, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(666.5965, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(720.0414, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(623.6997, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1582.5507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(918.3329, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(722.9815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1603.4033, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(525.4678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1478.6960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2906.4426, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(778.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1624.1638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1040.6456, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1928.2446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1434.7377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2307.4521, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(948.6646, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.16068052930056712, 'recall': 0.302491103202847, 'f1': 0.20987654320987656, 'number': 281}, 'P': {'precision': 0.5181347150259067, 'recall': 0.20876826722338204, 'f1': 0.2976190476190476, 'number': 479}, 'overall_precision': 0.2562326869806094, 'overall_recall': 0.24342105263157895, 'overall_f1': 0.2496626180836707, 'overall_accuracy': 0.5632276598961746}\n",
            "------------EPOCH 9---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1277.7159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1195.4622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1453.6163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1065.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(647.8287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(564.7305, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(876.9418, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(925.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(600.9648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(658.1469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(634.4450, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1144.3854, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(617.0439, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1377.9878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1655.9913, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1047.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(996.9426, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(486.8370, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(942.3219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(581.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1078.7883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(737.6174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1081.8098, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(542.9482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1447.7942, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2979.2864, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1115.9581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1306.1770, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(622.6458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(596.7285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(586.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1514.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1196.3765, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(902.0760, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1843.6912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(561.0280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1303.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3431.3330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(758.6979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1784.8088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(909.2834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1726.1735, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1257.8813, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2038.9294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(940.7672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3006134969325153, 'recall': 0.17437722419928825, 'f1': 0.2207207207207207, 'number': 281}, 'P': {'precision': 0.47042640990371387, 'recall': 0.7139874739039666, 'f1': 0.5671641791044776, 'number': 479}, 'overall_precision': 0.4393258426966292, 'overall_recall': 0.5144736842105263, 'overall_f1': 0.47393939393939394, 'overall_accuracy': 0.6647850410765587}\n",
            "------------EPOCH 10---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1754.4492, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1394.7751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2074.2944, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1331.2949, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(770.9728, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(759.4559, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1092.1567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(928.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(610.1672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(709.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(765.4339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1357.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(582.2308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1240.7939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1463.9484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(914.1210, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(946.2062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(496.9734, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(846.1018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(464.8581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(906.1170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(709.0692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1033.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(478.3297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1538.2035, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2923.6963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1102.9307, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1375.7853, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(528.7201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(505.3514, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(471.4702, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1192.8929, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(692.9333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(575.7404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1352.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(444.7164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1252.3246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2449.9023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(681.7048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1365.4690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(878.4875, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1665.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1364.0996, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2069.4512, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(816.4515, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.27479338842975204, 'recall': 0.47330960854092524, 'f1': 0.3477124183006535, 'number': 281}, 'P': {'precision': 0.5319148936170213, 'recall': 0.5219206680584552, 'f1': 0.5268703898840885, 'number': 479}, 'overall_precision': 0.40146750524109015, 'overall_recall': 0.5039473684210526, 'overall_f1': 0.44690781796966156, 'overall_accuracy': 0.6342926263797187}\n",
            "------------EPOCH 11---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1142.7581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1045.4939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1399.0619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(906.4766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(432.1169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(339.1313, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(696.9834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(620.2222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(424.9077, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(463.5815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(462.6172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1039.3412, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(506.8072, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1057.7585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1262.7589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(802.8071, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(703.3706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(377.7166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(691.2546, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(395.6956, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(840.4680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(590.0359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(798.6323, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(369.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1409.0029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2537.8188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(824.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1115.1731, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(575.0764, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(547.8412, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(494.1840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1279.3892, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(568.0166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(447.8226, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1294.1748, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(415.3568, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(869.7714, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1886.9045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(562.8312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(968.8112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(632.0975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1328.1774, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1012.5748, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1567.0513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(660.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.2479740680713128, 'recall': 0.5444839857651246, 'f1': 0.34075723830734966, 'number': 281}, 'P': {'precision': 0.536, 'recall': 0.4196242171189979, 'f1': 0.4707259953161593, 'number': 479}, 'overall_precision': 0.35685483870967744, 'overall_recall': 0.46578947368421053, 'overall_f1': 0.4041095890410959, 'overall_accuracy': 0.57769265662013}\n",
            "------------EPOCH 12---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1050.8325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1057.9327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1336.5927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(834.3691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(460.2325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(320.9831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(826.1566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(561.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(364.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(447.7894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(497.3615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1450.9387, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(637.3445, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1239.5532, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1404.7539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(782.5967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(744.2750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(370.9897, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(744.2142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(464.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(685.3505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(451.5132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(688.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(369.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1048.0352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2164.8008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(775.4496, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1098.7544, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(326.5992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(376.6863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(328.6379, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(934.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(507.6416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(418.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1067.0859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(349.7823, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1086.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1952.8375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(777.8572, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1265.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(691.5293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1608.8352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(958.5419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1521.7683, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(473.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3076923076923077, 'recall': 0.498220640569395, 'f1': 0.38043478260869573, 'number': 281}, 'P': {'precision': 0.6706443914081146, 'recall': 0.5866388308977035, 'f1': 0.6258351893095768, 'number': 479}, 'overall_precision': 0.4816933638443936, 'overall_recall': 0.5539473684210526, 'overall_f1': 0.5152998776009792, 'overall_accuracy': 0.6578297464845522}\n",
            "------------EPOCH 13---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(785.5110, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(676.4979, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(927.5903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(479.8112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(235.6470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(177.8705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(439.2184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(367.7709, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(246.9494, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(273.0571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(261.8077, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(781.9935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(489.2213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(960.8624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1165.7562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(669.2837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(747.2291, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(319.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(670.8685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(406.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(610.1852, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(399.8287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(646.0530, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(347.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1065.2185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2195.3389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(741.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1397.2701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(332.3586, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(433.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(409.5378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1097.8690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(431.4589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(286.1822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1176.1246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(367.6741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(855.7407, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1643.8118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(436.4341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(780.7967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(441.5881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(987.3105, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(673.2160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1100.7725, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(513.6294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.23772102161100198, 'recall': 0.4306049822064057, 'f1': 0.3063291139240506, 'number': 281}, 'P': {'precision': 0.6640625, 'recall': 0.17745302713987474, 'f1': 0.2800658978583196, 'number': 479}, 'overall_precision': 0.32339089481946626, 'overall_recall': 0.2710526315789474, 'overall_f1': 0.29491768074445246, 'overall_accuracy': 0.5636308653797691}\n",
            "------------EPOCH 14---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1179.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1060.0254, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1427.7245, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(804.0010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(493.7676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(316.0601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(594.0244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(682.4469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(388.5731, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(436.4420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(518.8751, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(776.8286, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(357.3903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(751.6249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(831.0646, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(566.3918, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(423.5830, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(234.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(403.3629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(218.7082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(514.9249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(376.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(523.5934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(236.8893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(940.6788, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1727.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(516.1873, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(875.1580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(332.5812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(322.4553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(294.2296, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(849.2242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(320.8108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(227.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(836.6912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(307.1162, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(658.2157, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1152.7494, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(414.7158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(567.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(414.7169, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(913.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(665.6755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(940.9739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(398.9143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.2920863309352518, 'recall': 0.7224199288256228, 'f1': 0.41598360655737715, 'number': 281}, 'P': {'precision': 0.7346938775510204, 'recall': 0.30062630480167013, 'f1': 0.4266666666666667, 'number': 479}, 'overall_precision': 0.3894500561167228, 'overall_recall': 0.45657894736842103, 'overall_f1': 0.420351302241066, 'overall_accuracy': 0.5920568519731868}\n",
            "------------EPOCH 15---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(701.7894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(573.8090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(711.7543, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(415.6573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(228.7024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(160.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(334.6030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(305.3595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(269.5558, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(302.6241, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(296.5898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(544.2391, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(423.5587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(786.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(786.1278, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(657.8392, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(352.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(223.4299, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(368.4798, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(218.3233, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(362.4577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(248.0533, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(335.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(145.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(724.5083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1185.0853, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(288.7595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(571.7242, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(282.7370, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(227.4120, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(246.1928, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(763.1099, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(470.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(238.2535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1014.0586, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(364.6711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1080.1375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1870.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(569.1983, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(736.9879, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(461.3711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1078.2882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(542.4777, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(791.5876, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(234.4018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.28463855421686746, 'recall': 0.6725978647686833, 'f1': 0.39999999999999997, 'number': 281}, 'P': {'precision': 0.7261146496815286, 'recall': 0.23799582463465555, 'f1': 0.3584905660377358, 'number': 479}, 'overall_precision': 0.3690621193666261, 'overall_recall': 0.3986842105263158, 'overall_f1': 0.38330170777988615, 'overall_accuracy': 0.5915024444332443}\n",
            "------------EPOCH 16---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(543.5004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(458.8325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(573.9294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(264.9589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(265.6820, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(182.2497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(327.7787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(355.5564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(604.3832, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(659.9469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(539.6992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(985.0128, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1039.4517, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2103.3193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2038.8472, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1736.8915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(736.6281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(495.2602, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(832.3218, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(429.3542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(384.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(373.2483, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(408.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(173.9194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(559.7361, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(977.6249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(244.8476, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(452.9136, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(200.6106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(164.8015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(181.0697, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(491.2161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(479.5017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(197.0024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(804.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(319.3994, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1301.4249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2013.3018, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(728.3182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(899.5653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1006.6833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2157.5364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1072.3020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1794.2738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(661.6266, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.27450980392156865, 'recall': 0.1494661921708185, 'f1': 0.19354838709677422, 'number': 281}, 'P': {'precision': 0.5543478260869565, 'recall': 0.7453027139874739, 'f1': 0.6357969723953696, 'number': 479}, 'overall_precision': 0.5006273525721455, 'overall_recall': 0.525, 'overall_f1': 0.51252408477842, 'overall_accuracy': 0.6996119147220402}\n",
            "------------EPOCH 17---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(1632.3943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1121.8115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1816.5870, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(888.9857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(437.0095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(423.2359, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(530.7030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(494.4167, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(302.6596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(366.2285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(351.0276, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(596.3473, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(322.7073, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(596.8172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(810.1948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(438.3082, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(433.3558, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(325.7900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(491.1571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(266.2288, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(745.3461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(678.4583, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(919.5226, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(387.3322, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2120.3303, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3444.3799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(912.8639, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1123.5186, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(614.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(390.4963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(485.3763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1506.2334, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(732.7327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(883.4520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1428.6919, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(288.4012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(557.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1777.3901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(435.7545, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(971.9385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(430.5753, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(813.3096, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(634.0671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(911.4055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(302.6535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.330188679245283, 'recall': 0.3736654804270463, 'f1': 0.35058430717863104, 'number': 281}, 'P': {'precision': 0.5652892561983471, 'recall': 0.7139874739039666, 'f1': 0.6309963099630997, 'number': 479}, 'overall_precision': 0.48429035752979416, 'overall_recall': 0.5881578947368421, 'overall_f1': 0.5311942959001782, 'overall_accuracy': 0.6943198427498614}\n",
            "------------EPOCH 18---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(827.8582, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(566.0970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(846.6140, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(424.6103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(360.1038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(346.7149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(539.3909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(449.9443, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(388.8859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(601.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(595.4659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1094.4639, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(510.5981, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1005.8429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1478.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(929.7630, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(637.4448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(271.4558, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(750.4561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(447.6869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(610.9653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(382.5931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(569.2415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(204.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(739.0836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1454.0771, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(525.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(737.8773, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(201.3710, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(169.5108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(195.0093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(525.1077, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(285.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(229.3520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(516.3889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(167.4429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(375.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(808.7998, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(258.0421, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(568.0143, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(300.5696, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(636.9274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(414.6464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(577.1415, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(266.5027, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.33986928104575165, 'recall': 0.5551601423487544, 'f1': 0.4216216216216216, 'number': 281}, 'P': {'precision': 0.6842105263157895, 'recall': 0.48851774530271397, 'f1': 0.5700365408038977, 'number': 479}, 'overall_precision': 0.4868913857677903, 'overall_recall': 0.5131578947368421, 'overall_f1': 0.49967969250480465, 'overall_accuracy': 0.6925558187591351}\n",
            "------------EPOCH 19---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(424.0038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(397.9675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(489.5369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(266.7306, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(191.1320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(125.9208, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(206.9866, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(230.4164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(152.1344, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(163.3302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(174.3631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(312.3543, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(213.3147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(379.8235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(391.3448, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(293.8278, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(255.0385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(186.4268, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(238.1519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(106.7428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(254.3301, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(244.9374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(265.2189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(158.8636, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(548.5471, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(1001.3881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(223.7451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(426.7231, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(171.7058, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(115.6324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(228.2336, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(412.0719, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(233.9849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(159.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(382.0707, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(140.7505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(208.6512, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(513.7216, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(163.4539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(365.3887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(161.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(420.4899, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(233.0326, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(317.4506, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(147.9068, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3709677419354839, 'recall': 0.4092526690391459, 'f1': 0.38917089678510997, 'number': 281}, 'P': {'precision': 0.6384615384615384, 'recall': 0.6931106471816284, 'f1': 0.6646646646646647, 'number': 479}, 'overall_precision': 0.5385542168674698, 'overall_recall': 0.5881578947368421, 'overall_f1': 0.5622641509433962, 'overall_accuracy': 0.7114560758026309}\n",
            "------------EPOCH 20---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(399.0740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(302.5349, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(514.8096, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(170.8320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(170.1837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(147.6779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(243.8514, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(153.0183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(122.4350, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(152.4684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(131.3620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(302.3803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(169.9104, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(385.5827, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(346.5147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(242.2964, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(194.6567, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(119.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(217.3178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(73.5428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(188.9271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(158.9705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(154.3354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(383.3132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(484.1682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(113.9947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(223.5934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.2324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.9179, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(149.3902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(208.9117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(119.4447, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(53.9737, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(210.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(90.6062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(125.2735, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(355.9588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.9563, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(289.7880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(150.1021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(324.4188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(168.2859, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(270.3246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(146.6506, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.31333333333333335, 'recall': 0.501779359430605, 'f1': 0.3857729138166895, 'number': 281}, 'P': {'precision': 0.6354430379746835, 'recall': 0.524008350730689, 'f1': 0.574370709382151, 'number': 479}, 'overall_precision': 0.463905325443787, 'overall_recall': 0.5157894736842106, 'overall_f1': 0.48847352024922114, 'overall_accuracy': 0.6832820926364599}\n",
            "------------EPOCH 21---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(197.9085, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(163.4769, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(264.7645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(111.0027, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(152.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(81.2667, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(121.2292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(89.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(88.4755, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.5885, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.4615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(195.2413, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(138.3601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(170.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(230.6382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(147.7054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(109.2640, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(107.3553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(179.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(129.9115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(120.8283, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.3562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(395.7435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(380.3535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.1759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(172.2792, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(91.7909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.5461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(111.9123, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(207.7974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(103.9283, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.8943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(134.8008, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(100.8306, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(133.9599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(218.7379, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.8618, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(217.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(81.4715, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(192.1349, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(105.9338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(161.5553, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.5429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.34705882352941175, 'recall': 0.4199288256227758, 'f1': 0.3800322061191626, 'number': 281}, 'P': {'precision': 0.6340425531914894, 'recall': 0.6221294363256785, 'f1': 0.6280295047418335, 'number': 479}, 'overall_precision': 0.5135802469135803, 'overall_recall': 0.5473684210526316, 'overall_f1': 0.5299363057324841, 'overall_accuracy': 0.7092384456428608}\n",
            "------------EPOCH 22---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(149.2669, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(148.1120, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(215.6896, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.6488, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(121.1978, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(88.3865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(123.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(91.9207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(77.2606, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(91.3637, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(159.8401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(96.6543, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(185.7562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(165.0946, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(92.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(81.3482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(90.2019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(86.0059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.1803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(107.0690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(92.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(121.8629, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.4724, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(255.5956, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(311.3251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(63.1516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(155.9420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.8586, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(85.2787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(131.1449, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(146.7062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(103.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.5257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(127.1224, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(85.0015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(106.6136, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(173.7097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.1919, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(206.6609, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(64.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(171.8490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(105.0054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(157.3556, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.9639, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.32682926829268294, 'recall': 0.47686832740213525, 'f1': 0.3878437047756874, 'number': 281}, 'P': {'precision': 0.6420047732696897, 'recall': 0.5615866388308977, 'f1': 0.5991091314031181, 'number': 479}, 'overall_precision': 0.48612786489746684, 'overall_recall': 0.5302631578947369, 'overall_f1': 0.5072372561359346, 'overall_accuracy': 0.6818708734438789}\n",
            "------------EPOCH 23---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(116.5766, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(100.1474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(135.7580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.7516, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(103.0342, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(112.0097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.2132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(62.3811, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.1301, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.4696, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(128.4603, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(85.4805, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(110.6903, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(122.8399, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(66.5737, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.5762, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.0928, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(53.1839, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(87.7867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(79.4853, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.8150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(139.9721, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(209.6894, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.3493, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(132.7798, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(64.9795, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.6947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(79.6606, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(95.9803, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.9000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.7638, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(89.8090, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(66.5006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(92.4060, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(126.9923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(59.9585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(182.8320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.3273, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(94.2654, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(102.3145, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.7646, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.35294117647058826, 'recall': 0.5124555160142349, 'f1': 0.41799709724238027, 'number': 281}, 'P': {'precision': 0.6431924882629108, 'recall': 0.5720250521920668, 'f1': 0.605524861878453, 'number': 479}, 'overall_precision': 0.5011990407673861, 'overall_recall': 0.55, 'overall_f1': 0.5244667503136763, 'overall_accuracy': 0.6883221611813921}\n",
            "------------EPOCH 24---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(83.0570, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(62.4786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(84.4280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.6102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(89.6165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.9904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(83.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.5399, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.2473, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.8102, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.5704, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.4963, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.0423, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(107.5013, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(89.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.6204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.5551, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.4937, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.4590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.0267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(59.8739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.0394, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(69.1284, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(90.9070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(160.6219, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.7613, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(104.0149, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.5413, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.9350, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.0985, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(53.3229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.3542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.3335, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(52.2959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(58.7213, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(84.8850, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.5244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(147.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.6861, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(61.4495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(71.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.6490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.9673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3301204819277108, 'recall': 0.4875444839857651, 'f1': 0.3936781609195402, 'number': 281}, 'P': {'precision': 0.6445497630331753, 'recall': 0.5678496868475992, 'f1': 0.6037735849056605, 'number': 479}, 'overall_precision': 0.4886499402628435, 'overall_recall': 0.5381578947368421, 'overall_f1': 0.512210394489668, 'overall_accuracy': 0.6855501234816793}\n",
            "------------EPOCH 25---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(56.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.7984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.3780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.4767, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(76.7235, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.3266, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(73.3664, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.6935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.8228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.4726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.2827, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.9239, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(76.4855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.5342, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.9237, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.7438, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.2000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.6491, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.5211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.4337, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.5159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.2485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.9406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(76.1329, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(144.6839, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.9334, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(90.8740, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(48.8905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.8870, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.1387, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.7322, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.2706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.1588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.6529, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.7692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.4942, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.8173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.6992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(121.7555, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.7091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.9388, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(62.9763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(68.0593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.3414, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3276283618581907, 'recall': 0.47686832740213525, 'f1': 0.38840579710144923, 'number': 281}, 'P': {'precision': 0.6405529953917051, 'recall': 0.5803757828810021, 'f1': 0.6089813800657174, 'number': 479}, 'overall_precision': 0.4887307236061684, 'overall_recall': 0.5421052631578948, 'overall_f1': 0.5140361821584529, 'overall_accuracy': 0.688775767350436}\n",
            "------------EPOCH 26---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(45.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.6021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.3192, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.0581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(67.8783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(62.9822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5948, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.0318, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.0163, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.3741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.4550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(54.5266, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(57.5010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.2912, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.5119, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.7697, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.4526, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.5887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.9005, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.7313, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.3733, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.4400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(67.0020, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(110.6746, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(66.0599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.4189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.0322, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.7471, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.2800, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.6056, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.7838, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.2608, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.3955, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.9851, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(53.0455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.8717, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(105.3010, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.2437, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.6787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(56.4901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.9364, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.0158, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3424317617866005, 'recall': 0.49110320284697506, 'f1': 0.4035087719298246, 'number': 281}, 'P': {'precision': 0.636986301369863, 'recall': 0.5824634655532359, 'f1': 0.608505997818975, 'number': 479}, 'overall_precision': 0.4958382877526754, 'overall_recall': 0.5486842105263158, 'overall_f1': 0.5209244222361025, 'overall_accuracy': 0.6912454009374528}\n",
            "------------EPOCH 27---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(36.7471, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.5713, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.1103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.8480, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(56.2451, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.3298, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.4771, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.3327, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.7929, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.6670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.6783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.6580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(38.7199, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.4026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(47.8436, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.4814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.4159, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.0504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.8206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.3935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.7483, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.7970, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.8497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(60.8092, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(90.7375, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.9705, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.0747, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.4218, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.8834, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.8302, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.7990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.9217, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.6135, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.9114, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.1680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.1385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(91.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.2040, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.5966, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.7261, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.8330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.7965, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3333333333333333, 'recall': 0.48398576512455516, 'f1': 0.39477503628447025, 'number': 281}, 'P': {'precision': 0.6298850574712643, 'recall': 0.5720250521920668, 'f1': 0.599562363238512, 'number': 479}, 'overall_precision': 0.4863582443653618, 'overall_recall': 0.5394736842105263, 'overall_f1': 0.511540860885839, 'overall_accuracy': 0.68847336323774}\n",
            "------------EPOCH 28---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(29.7425, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.8063, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.7678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.0472, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(44.7474, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.4631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.3070, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.4250, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.7026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.9221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.0961, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.5372, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.5761, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.3910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.5891, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.0406, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.7182, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.8287, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.3663, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4668, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.6849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.1579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.8258, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.7919, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(51.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(80.0675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.7318, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(37.7457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.2341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.4155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.1125, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.2420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.8007, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.6196, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.4773, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.7000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.2947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.7571, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.2863, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(77.5541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.6347, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.3061, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.4867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.4468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3316953316953317, 'recall': 0.4804270462633452, 'f1': 0.3924418604651163, 'number': 281}, 'P': {'precision': 0.6386363636363637, 'recall': 0.5866388308977035, 'f1': 0.6115342763873776, 'number': 479}, 'overall_precision': 0.4911452184179457, 'overall_recall': 0.5473684210526316, 'overall_f1': 0.5177349097697572, 'overall_accuracy': 0.6882213598104934}\n",
            "------------EPOCH 29---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(24.8091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.8682, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.7686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.6747, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.9220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.9484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(39.7281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.1849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.9411, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.8087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.8775, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.8265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.8022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(33.7390, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.3029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.5596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.2399, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.4953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.4673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.7897, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.8531, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.0089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.4446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.6401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(49.5464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(72.6264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.4848, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.0575, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.1378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.5550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.8847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.4092, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.1655, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.4749, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.6860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.3550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.5990, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.7925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(67.4356, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.2660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(30.1377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(43.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.7488, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.32997481108312343, 'recall': 0.46619217081850534, 'f1': 0.3864306784660767, 'number': 281}, 'P': {'precision': 0.6300448430493274, 'recall': 0.5866388308977035, 'f1': 0.6075675675675677, 'number': 479}, 'overall_precision': 0.4887307236061684, 'overall_recall': 0.5421052631578948, 'overall_f1': 0.5140361821584529, 'overall_accuracy': 0.6871629454160577}\n",
            "------------EPOCH 30---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(22.1144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.4161, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.1446, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.1539, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.0680, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.4424, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.5604, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.6649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.6168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.9496, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.1317, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.0197, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.1858, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.8672, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.4072, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.2749, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.2083, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.9452, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.8577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.1904, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.5384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.1430, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(42.8081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(70.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.5767, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.4115, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.9240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.3097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.3860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.5270, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.9423, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.7490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.3376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.3045, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.2345, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.4051, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.4050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(59.4699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.4444, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.6490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(34.2975, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.5670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.5814, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.33658536585365856, 'recall': 0.49110320284697506, 'f1': 0.3994211287988423, 'number': 281}, 'P': {'precision': 0.6400911161731208, 'recall': 0.5866388308977035, 'f1': 0.6122004357298475, 'number': 479}, 'overall_precision': 0.49352179034157834, 'overall_recall': 0.5513157894736842, 'overall_f1': 0.5208203853325047, 'overall_accuracy': 0.6883221611813921}\n",
            "------------EPOCH 31---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(19.5595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.7992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.7598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(32.1582, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.7601, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.0346, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.5938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.4905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.8930, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.7920, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.4987, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.6797, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.8222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.0139, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.2564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.5136, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.6559, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.8206, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.4226, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.8369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.4246, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(36.5345, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(61.5264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.7410, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.0252, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.6895, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.9854, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.7113, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.8716, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.3324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.8520, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.7334, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.1729, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.5016, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.3855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(52.3207, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.8194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.9502, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.5889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.7324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3229665071770335, 'recall': 0.4804270462633452, 'f1': 0.3862660944206009, 'number': 281}, 'P': {'precision': 0.62877030162413, 'recall': 0.5657620041753654, 'f1': 0.5956043956043956, 'number': 479}, 'overall_precision': 0.47820965842167257, 'overall_recall': 0.5342105263157895, 'overall_f1': 0.5046612802983219, 'overall_accuracy': 0.6854493221107807}\n",
            "------------EPOCH 32---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(17.4109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.1573, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.7017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.7121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(28.3000, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.3898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.9373, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.1939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.9635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.8695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.5523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.2847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.6419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.4457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(19.7150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.6200, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.9483, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.9507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.9478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.6048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.6764, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(31.7464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(55.9093, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.3048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.3986, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(25.6690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.4762, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.2686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.2648, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.0886, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.1831, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.7923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(21.1967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.1232, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.9385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.7021, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(45.9309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.9986, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.6160, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.1308, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.1417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3261390887290168, 'recall': 0.48398576512455516, 'f1': 0.38968481375358166, 'number': 281}, 'P': {'precision': 0.6183908045977011, 'recall': 0.5615866388308977, 'f1': 0.5886214442013129, 'number': 479}, 'overall_precision': 0.4753521126760563, 'overall_recall': 0.5328947368421053, 'overall_f1': 0.5024813895781638, 'overall_accuracy': 0.681114863162139}\n",
            "------------EPOCH 33---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(15.1222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.9605, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.1550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.6435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(26.5276, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.5028, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.8889, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.4799, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.4197, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.1188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.6741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.0151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.3678, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.5111, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.7062, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.0810, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.7646, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.5469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.0908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.8643, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.3046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(27.0997, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(50.4275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.9183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.7077, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.3940, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.8059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(13.2953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.0661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.9910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.6887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.9750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(18.9384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.1902, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.2743, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(40.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.7079, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.8214, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.9495, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.9652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.6243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3237410071942446, 'recall': 0.4804270462633452, 'f1': 0.3868194842406876, 'number': 281}, 'P': {'precision': 0.6183908045977011, 'recall': 0.5615866388308977, 'f1': 0.5886214442013129, 'number': 479}, 'overall_precision': 0.47417840375586856, 'overall_recall': 0.531578947368421, 'overall_f1': 0.5012406947890818, 'overall_accuracy': 0.6813164659039362}\n",
            "------------EPOCH 34---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(12.6490, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4927, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.9134, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.2029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.8417, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.7524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(24.9843, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.8631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.5872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.0947, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.9585, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.2900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.4528, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.6384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.2038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.7402, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.1645, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.9479, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.1130, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.3473, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.8878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.9155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.7293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.1950, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(46.0507, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.5618, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.3815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.1425, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.3002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.6559, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.1436, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.1602, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.2616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.6893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.6596, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.7441, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.9292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(35.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.2909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.8248, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.8059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.5488, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.2435, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.3269689737470167, 'recall': 0.4875444839857651, 'f1': 0.3914285714285714, 'number': 281}, 'P': {'precision': 0.625, 'recall': 0.5636743215031316, 'f1': 0.592755214050494, 'number': 479}, 'overall_precision': 0.4782608695652174, 'overall_recall': 0.5355263157894737, 'overall_f1': 0.505276225946617, 'overall_accuracy': 0.6819212741293281}\n",
            "------------EPOCH 35---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loss:  tensor(10.3743, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.8462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.0559, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.2007, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.0039, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.7272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.3347, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.6484, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.7294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.5985, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.5779, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.4750, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.2883, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(10.1787, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(8.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.7910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.8893, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(4.6320, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(2.9172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.7420, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.3561, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.1002, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(9.0497, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(20.7647, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(41.6455, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(16.1454, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.3444, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(17.2939, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(12.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(6.5170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.5106, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.8887, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(7.6812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(15.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.1466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(14.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.6642, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(29.2024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(5.9204, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(11.7369, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(23.0099, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(22.4324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Loss:  tensor(3.9144, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'C': {'precision': 0.324582338902148, 'recall': 0.48398576512455516, 'f1': 0.3885714285714285, 'number': 281}, 'P': {'precision': 0.625866050808314, 'recall': 0.5657620041753654, 'f1': 0.594298245614035, 'number': 479}, 'overall_precision': 0.47769953051643194, 'overall_recall': 0.5355263157894737, 'overall_f1': 0.5049627791563276, 'overall_accuracy': 0.6815180686457336}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mi7LRmfIYbR"
      },
      "source": [
        "### Rough -- Checking dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD9kGw_svbXM",
        "outputId": "b2838b14-a51e-4129-bb8c-20b274bb7a1c"
      },
      "source": [
        "\" \".join(\" mY name is \".split())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'mY name is'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6-oVkplUCJh"
      },
      "source": [
        "def get_datasets():\n",
        "    train_dataset, valid_dataset, test_dataset = load_dataset(tokenizer=tokenizer,\n",
        "                                                              train_sz=80,\n",
        "                                                              test_sz=20,\n",
        "                                                              mask_tokens=discourse_markers)\n",
        "    return train_dataset, valid_dataset, test_dataset"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3qMGQ5GOzbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57323397-ef83-477b-a59d-7405173bb62c"
      },
      "source": [
        "train_dataset, _, test_dataset = get_datasets()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'change-my-view-modes' already exists and is not an empty directory.\n",
            "2021-08-29 07:42:38.410841: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2021-08-29 07:42:38.411592: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzdpyzvKIfM8",
        "outputId": "8531f009-4bed-4ea9-daa4-d76d023d52e9"
      },
      "source": [
        "for tokenized_threads, masked_threads, comp_type_labels, _ in test_dataset:\n",
        "    tokenized_threads, masked_threads, comp_type_labels = tokenized_threads[0], masked_threads[0], comp_type_labels[0]\n",
        "    for tokenized_thread, masked_thread, comp_type_label in zip(tokenized_threads, masked_threads, comp_type_labels):\n",
        "        print(comp_type_label[:100])\n",
        "        print(tokenized_thread[:100])\n",
        "        print(tokenizer.decode(tokenized_thread[:500]))\n",
        "        start, end = 0, 0\n",
        "        prev_type = \"other\"\n",
        "        i = 0\n",
        "        while i<tokenized_thread.shape[0]:\n",
        "            if comp_type_label[i]==ac_dict[\"O\"]:\n",
        "                if prev_type==\"other\":\n",
        "                    end += 1\n",
        "                else:\n",
        "                    print(\"Component: \", tokenizer.decode(tokenized_thread[start:end+1]), \" of type: \", prev_type, tokenized_thread[start:end+1])\n",
        "                    print(\"Masked Component: \", tokenizer.decode(masked_thread[start:end+1]), \" of type: \", prev_type, masked_thread[start:end+1])\n",
        "                    start = i\n",
        "                    end = i\n",
        "                    prev_type=\"other\"\n",
        "                \n",
        "            if comp_type_label[i] in [ac_dict[\"B-C\"], ac_dict[\"B-P\"]]:\n",
        "                print(\"Component: \", tokenizer.decode(tokenized_thread[start:end+1]), \" of type: \", prev_type, tokenized_thread[start:end+1])\n",
        "                print(\"Masked Component: \", tokenizer.decode(masked_thread[start:end+1]), \" of type: \", prev_type, masked_thread[start:end+1])\n",
        "                start = i\n",
        "                end = i\n",
        "                prev_type = \"Claim\" if comp_type_label[i]==ac_dict[\"B-C\"] else \"Premise\"\n",
        "            \n",
        "            if comp_type_label[i] in [ac_dict[\"I-C\"], ac_dict[\"I-P\"]]:\n",
        "                end += 1\n",
        "            \n",
        "            i+=1\n",
        "        break\n",
        "    break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2\n",
            " 2 2 2 2 0 0 0 0 1 2 2 2 2 2 2 2 2 2 2 2 2 3 4 4 4 4]\n",
            "[    0 18814   846    35  7978     9  1901    16   145   551   350   444\n",
            " 50270 50268 50268  1121     5    94   367   688    52   348    56    80\n",
            "  1307  1061  1369    11     5   232     6   258     9    61    58  1726\n",
            "    30  3510  8941     7    22  3519     9  1901     4    22    20    78\n",
            "   145     5 11597     9  6366    81    20 21902     6     8   452     5\n",
            "  1094    23     5  4088     9    10 33937  4320    11  2201     4 50268\n",
            "   100  1819   923    84   481  1901    53     7   162  1437  8585    16\n",
            "    10   699   516   227 20203   110    78  8322   235    36  1437    22\n",
            "   270  1284 29384   328]\n",
            "<s>CMV: Freedom of speech is being taken too far [USER0] [NEWLINE] [NEWLINE] In the last few weeks we've had two huge events happen in the world, both of which were caused by matters relating to \" freedom of speech. \" The first being the hacking of Sony over The Interview, and today the shooting at the offices of a satirical magazine in Paris. [NEWLINE] I certainly value our free speech but to me there is a clear line between exercising your first amendment right (  \" President Obama sucks! \" etc ) and doing things that are known to be offensive to other cultures (  Satirical cartoons of prophets, assassinating leaders, etc ). [NEWLINE] [NEWLINE]  Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome.  [NEWLINE] [USER1] [NEWLINE] [NEWLINE] [STARTQ] Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome. [ENDQ] [NEWLINE] Sure, but that doesn't mean we condone the bully's actions and don't punish the bullies for acting. [NEWLINE] We want to live in a world without bullies, whether those bullies act on behalf of beliefs, religions, countries, or even out own governments. [NEWLINE]  Complete freedom in the expression of any idea, offensive or not, is a major element of that world. [NEWLINE] [NEWLINE]  If you want to protect the freedom to speak for any of us, you have to protect the freedom to speak for all of us. [NEWLINE] [NEWLINE] [USER0] [NEWLINE] I certainly agree with your points - I didn't mean to imply that I was only for * * some * * freedom of speech. [NEWLINE] I just think lately there's been a lot of antagonistic material being published and everyone cries freedom of speech when certain groups get upset. [NEWLINE] [NEWLINE]  Why can't America be the bigger person and say \" Ok, we won't publish certain types of material, not because we're afraid of you but because we respect your views. \"  [NEWLINE] Is that so hard? [NEWLINE] [NEWLINE] </s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "Component:  <s>CM  of type:  other [    0 18814]\n",
            "Masked Component:  <s>CM  of type:  other [    0 18814]\n",
            "Component:  CMV: Freedom of speech is being taken too far  of type:  Claim [18814   846    35  7978     9  1901    16   145   551   350   444]\n",
            "Masked Component:  CMV: Freedom of speech is being taken too far  of type:  Claim [18814   846    35  7978     9  1901    16   145   551   350   444]\n",
            "Component:  [USER0] [NEWLINE] [NEWLINE] In the last few weeks we've had two huge events happen in the world, both of which were caused by matters relating to \" freedom of speech. \" The first being the hacking of Sony over The Interview, and today the shooting at the offices of a satirical magazine in Paris. [NEWLINE]  of type:  other [50270 50268 50268  1121     5    94   367   688    52   348    56    80\n",
            "  1307  1061  1369    11     5   232     6   258     9    61    58  1726\n",
            "    30  3510  8941     7    22  3519     9  1901     4    22    20    78\n",
            "   145     5 11597     9  6366    81    20 21902     6     8   452     5\n",
            "  1094    23     5  4088     9    10 33937  4320    11  2201     4 50268]\n",
            "Masked Component:  [USER0] [NEWLINE] [NEWLINE] In the last few weeks we've had two huge events happen in the world, both of which were caused by matters relating to \" freedom of speech. \" The first being the hacking of Sony over The Interview, and today the shooting at the offices of a satirical magazine in Paris. [NEWLINE]  of type:  other [50270 50268 50268  1121     5    94   367   688    52   348    56    80\n",
            "  1307  1061  1369    11     5   232     6   258     9    61    58  1726\n",
            "    30  3510  8941     7    22  3519     9  1901     4    22    20    78\n",
            "   145     5 11597     9  6366    81    20 21902     6     8   452     5\n",
            "  1094    23     5  4088     9    10 33937  4320    11  2201     4 50268]\n",
            "Component:  I certainly value our free speech  of type:  Claim [ 100 1819  923   84  481 1901]\n",
            "Masked Component:  I certainly value our free speech  of type:  Claim [ 100 1819  923   84  481 1901]\n",
            "Component:   but to me   of type:  other [  53    7  162 1437]\n",
            "Masked Component:  <mask> to me   of type:  other [50264     7   162  1437]\n",
            "Component:  there is a clear line between exercising your first amendment right (   of type:  Claim [ 8585    16    10   699   516   227 20203   110    78  8322   235    36\n",
            "  1437]\n",
            "Masked Component:  there is a clear line between exercising your first amendment right (   of type:  Claim [ 8585    16    10   699   516   227 20203   110    78  8322   235    36\n",
            "  1437]\n",
            "Component:   \" President Obama sucks! \" etc  of type:  Premise [   22   270  1284 29384   328    22  4753]\n",
            "Masked Component:   \" President Obama sucks! \" etc  of type:  Premise [   22   270  1284 29384   328    22  4753]\n",
            "Component:   ) and doing things that are known to be offensive to other cultures  of type:  Claim [ 4839     8   608   383    14    32   684     7    28  2555     7    97\n",
            " 13426]\n",
            "Masked Component:   ) and doing things that are known to be offensive to other cultures  of type:  Claim [ 4839     8   608   383    14    32   684     7    28  2555     7    97\n",
            " 13426]\n",
            "Component:   (   of type:  other [  36 1437]\n",
            "Masked Component:   (   of type:  other [  36 1437]\n",
            "Component:   Satirical cartoons of prophets, assassinating leaders, etc  of type:  Premise [ 8918   853  3569 32162     9 43346     6 39257 15647   917     6  4753]\n",
            "Masked Component:   Satirical cartoons of prophets, assassinating leaders, etc  of type:  Premise [ 8918   853  3569 32162     9 43346     6 39257 15647   917     6  4753]\n",
            "Component:   ). [NEWLINE] [NEWLINE]  of type:  other [32801 50268 50268]\n",
            "Masked Component:   ). [NEWLINE] [NEWLINE]  of type:  other [32801 50268 50268]\n",
            "Component:   Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome.   of type:  Claim [ 6259    42    16    10  1099 33460   111    53   114    47   224   402\n",
            " 32726  2787     7    10 23934     8    47   120   110  8446  5836     6\n",
            "    47   197    33  5291    14  4258     4  1437]\n",
            "Masked Component:   Perhaps this is a bad analogy -<mask><mask> you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome.   of type:  Claim [ 6259    42    16    10  1099 33460   111 50264 50264    47   224   402\n",
            " 32726  2787     7    10 23934     8    47   120   110  8446  5836     6\n",
            "    47   197    33  5291    14  4258     4  1437]\n",
            "Component:  [NEWLINE] [USER1] [NEWLINE] [NEWLINE] [STARTQ] Perhaps this is a bad analogy - but if you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome. [ENDQ] [NEWLINE]  of type:  other [50268 50271 50268 50268 50265 32458    42    16    10  1099 33460   111\n",
            "    53   114    47   224   402 32726  2787     7    10 23934     8    47\n",
            "   120   110  8446  5836     6    47   197    33  5291    14  4258     4\n",
            " 50266 50268]\n",
            "Masked Component:  [NEWLINE] [USER1] [NEWLINE] [NEWLINE] [STARTQ] Perhaps this is a bad analogy -<mask><mask> you say something antagonizing to a bully and you get your ass kicked, you should have anticipated that outcome. [ENDQ] [NEWLINE]  of type:  other [50268 50271 50268 50268 50265 32458    42    16    10  1099 33460   111\n",
            " 50264 50264    47   224   402 32726  2787     7    10 23934     8    47\n",
            "   120   110  8446  5836     6    47   197    33  5291    14  4258     4\n",
            " 50266 50268]\n",
            "Component:  Sure  of type:  Claim [32541]\n",
            "Masked Component:  Sure  of type:  Claim [32541]\n",
            "Component:  , but   of type:  other [   6   53 1437]\n",
            "Masked Component:  ,<mask>   of type:  other [    6 50264  1437]\n",
            "Component:  that doesn't mean we condone the bully's actions and don't punish the bullies for acting  of type:  Claim [ 6025   630    75  1266    52 35005     5 23934    18  2163     8   218\n",
            "    75 15392     5 33969    13  3501]\n",
            "Masked Component:  that doesn't mean we condone the bully's actions and don't punish the bullies for acting  of type:  Claim [ 6025   630    75  1266    52 35005     5 23934    18  2163     8   218\n",
            "    75 15392     5 33969    13  3501]\n",
            "Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Masked Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Component:  We want to live in a world without bullies, whether those bullies act on behalf of beliefs, religions, countries, or even out own governments  of type:  Premise [  170   236     7   697    11    10   232   396 33969     6   549   167\n",
            " 33969  1760    15  4137     9  9734     6 24664     6   749     6    50\n",
            "   190    66   308  3233]\n",
            "Masked Component:  We want to live in a world without bullies, whether those bullies act on behalf of beliefs, religions, countries, or even out own governments  of type:  Premise [  170   236     7   697    11    10   232   396 33969     6   549   167\n",
            " 33969  1760    15  4137     9  9734     6 24664     6   749     6    50\n",
            "   190    66   308  3233]\n",
            "Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Masked Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Component:   Complete freedom in the expression of any idea, offensive or not, is a major element of that world  of type:  Premise [18337  3519    11     5  8151     9   143  1114     6  2555    50    45\n",
            "     6    16    10   538  7510     9    14   232]\n",
            "Masked Component:   Complete freedom in the expression of any idea, offensive or not, is a major element of that world  of type:  Premise [18337  3519    11     5  8151     9   143  1114     6  2555    50    45\n",
            "     6    16    10   538  7510     9    14   232]\n",
            "Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Masked Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Component:   If you want to protect the freedom to speak for any of us, you have to protect the freedom to speak for all of us  of type:  Claim [ 318   47  236    7 1744    5 3519    7 1994   13  143    9  201    6\n",
            "   47   33    7 1744    5 3519    7 1994   13   70    9  201]\n",
            "Masked Component:  <mask> you want to protect the freedom to speak for any of us, you have to protect the freedom to speak for all of us  of type:  Claim [50264    47   236     7  1744     5  3519     7  1994    13   143     9\n",
            "   201     6    47    33     7  1744     5  3519     7  1994    13    70\n",
            "     9   201]\n",
            "Component:  . [NEWLINE] [NEWLINE] [USER0] [NEWLINE]  of type:  other [    4 50268 50268 50270 50268]\n",
            "Masked Component:  . [NEWLINE] [NEWLINE] [USER0] [NEWLINE]  of type:  other [    4 50268 50268 50270 50268]\n",
            "Component:  I certainly agree with your points  of type:  Claim [ 100 1819 2854   19  110  332]\n",
            "Masked Component:  I certainly agree with your points  of type:  Claim [ 100 1819 2854   19  110  332]\n",
            "Component:   -   of type:  other [ 111 1437]\n",
            "Masked Component:   -   of type:  other [ 111 1437]\n",
            "Component:  I didn't mean to imply that I was only for * * some * * freedom of speech  of type:  Claim [  100   399    75  1266     7 25696    14    38    21   129    13  1009\n",
            "  1009   103  1009  1009  3519     9  1901]\n",
            "Masked Component:  I didn't mean to imply that I was only for * * some * * freedom of speech  of type:  Claim [  100   399    75  1266     7 25696    14    38    21   129    13  1009\n",
            "  1009   103  1009  1009  3519     9  1901]\n",
            "Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Masked Component:  . [NEWLINE]  of type:  other [    4 50268]\n",
            "Component:  I just think lately there's been a lot of antagonistic material being published and everyone cries freedom of speech when certain groups get upset  of type:  Claim [  100    95   206 12056    89    18    57    10   319     9 32726  5580\n",
            "  1468   145  1027     8   961 25355  3519     9  1901    77  1402  1134\n",
            "   120  4904]\n",
            "Masked Component:  I just think lately there's been a lot of antagonistic material being published and everyone cries freedom of speech<mask> certain groups get upset  of type:  Claim [  100    95   206 12056    89    18    57    10   319     9 32726  5580\n",
            "  1468   145  1027     8   961 25355  3519     9  1901 50264  1402  1134\n",
            "   120  4904]\n",
            "Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Masked Component:  . [NEWLINE] [NEWLINE]  of type:  other [    4 50268 50268]\n",
            "Component:   Why can't America be the bigger person and say \" Ok, we won't publish certain types of material, not because we're afraid of you but because we respect your views. \"   of type:  Premise [ 2612    64    75   730    28     5  2671   621     8   224    22  5148\n",
            "     6    52   351    75 10732  1402  3505     9  1468     6    45   142\n",
            "    52   214  6023     9    47    53   142    52  2098   110  2728     4\n",
            "    22  1437]\n",
            "Masked Component:  <mask> can't America be the bigger person and say \" Ok, we won't publish certain types of material, not<mask> we're afraid of you<mask><mask> we respect your views. \"   of type:  Premise [50264    64    75   730    28     5  2671   621     8   224    22  5148\n",
            "     6    52   351    75 10732  1402  3505     9  1468     6    45 50264\n",
            "    52   214  6023     9    47 50264 50264    52  2098   110  2728     4\n",
            "    22  1437]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZnb1Nz-MX4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2601bebd-3989-40a5-af7d-91d578651823"
      },
      "source": [
        "import re\n",
        "re.sub(r\"\\s*</claim>([^\\s])\", r\"</claim> \\1\", \"<claim>my name is </claim>jeevesh.\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<claim>my name is</claim> jeevesh.'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5UVJb5jy178"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}